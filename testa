
// ==UserScript==
// @name          VideoFX Prompt Artisan (v8.0.1 - Accessibility & UI Polish)
// @namespace     https://labs.google/
// @version       8.0.1
// @description   Advanced prompt generation for VideoFX with a redesigned UI, new creative modes, accessibility improvements, and UI polish.
// @author        [Your Name] & Gemini
// @match         https://labs.google/fx/*
// @grant         GM_addStyle
// @grant         GM_setClipboard
// @grant         GM_getValue
// @grant         GM_setValue
// @grant         GM_download
// @grant         GM_xmlhttpRequest
// @downloadURL   [Your Greasyfork URL]
// @updateURL     [Your Greasyfork Meta URL]
// ==/UserScript==

(function () {
    'use strict';

    let hasInitialized = false; // Guard to prevent multiple initializations

    // --- Constants (ALL DEFINED FIRST) ---
    const SCRIPT_VERSION = '8.0.1';
    const API_ENDPOINT = 'https://labs.google/fx/api/trpc/videoFx.generateNextScenePrompts'; // Unchanged as per request
    const STORAGE_KEYS = { HISTORY: 'videoFx_artisan_history_v4', FAVORITES: 'videoFx_artisan_favorites_v2', ENHANCER_PRESETS: 'videoFx_artisan_enhancerPresets_v4', SELECTED_ARTISAN_MODE: 'videoFx_artisan_selectedMode_v3', SELECTED_AUDIO_LEVEL: 'videoFx_artisan_selectedAudioLevel_v3', SELECTED_STYLE: 'videoFx_artisan_selectedStyle_v2', ACTIVE_TOOL_ID: 'videoFx_artisan_activeToolId_v2' };
    const MAX_HISTORY_ITEMS = 50; const MAX_FAVORITES_ITEMS = 100; const DEFAULT_CANDIDATE_COUNT = 3; const DEFAULT_AUDIO_LEVEL = 'none'; const DEFAULT_STYLE_KEY = "";
    const VEO_STYLES = ["", "Cinematic", "Photorealistic", "Anime", "Claymation", "Watercolor", "Pixel Art", "Documentary", "Impressionistic", "Surreal", "Abstract", "Film Noir", "Cyberpunk", "Steampunk", "Vintage Film (Specify Era)", "Sketch Animation", "3D Cartoon"];
    const VEO_ASPECT_RATIOS_VALUES = ["", "16:9", "9:16", "1:1", "4:3", "3:4", "2.39:1"]; const VEO_ASPECT_RATIOS_DISPLAY = ["Any / Auto", "16:9 (Widescreen)", "9:16 (Vertical)", "1:1 (Square)", "4:3 (Standard TV)", "3:4 (Tall Standard)", "2.39:1 (Cinemascope)"];
    const VEO_CAMERA_ANGLES = ["", "Eye Level", "Low Angle", "High Angle", "Dutch Angle", "Birds Eye View", "Worms Eye View", "Over The Shoulder (OTS)"]; const VEO_CAMERA_MOVEMENTS = ["", "Static Shot", "Pan (Left/Right)", "Tilt (Up/Down)", "Dolly (In/Out)", "Tracking Shot", "Zoom (In/Out)", "Crane Shot", "Handheld", "Drone Shot"];
    const VEO_LIGHTING_CONDITIONS = ["", "Natural Light", "Studio Light", "Golden Hour", "Blue Hour", "Overcast", "Moonlight", "Backlight", "High Key", "Low Key (Chiaroscuro)", "Neon Glow"]; const VEO_DURATION_HINTS = ["", "Short (2-4s)", "Medium (5-8s)", "Long (9-15s)", "Very Long (16s+)"];
    const VEO_AUDIO_PROMPTING_LEVELS_VALUES = ['none', 'basic', 'detailed']; const VEO_AUDIO_PROMPTING_LEVELS_DISPLAY = ['None (Auto-Audio)', 'Basic Audio Cues', 'Detailed Audio Design'];
    const MAX_IMAGE_SIZE_BYTES = 5 * 1024 * 1024; const ALLOWED_IMAGE_TYPES = ['image/jpeg', 'image/png', 'image/webp', 'image/gif'];
    const SCHEMA_INPUTS = { composition_rule: { title: "Compositional Rule", enum: ["Default", "Rule of Thirds", "Golden Ratio / Spiral", "Centered Framing / Symmetry", "Leading Lines", "Diagonal Lines", "Triangle Composition", "Frame Within a Frame", "Negative Space Focus", "Dynamic Symmetry"], default: "Default", description: "Guides visual arrangement of elements for aesthetic impact and storytelling."}, shot_size: { title: "Shot Size / Framing", enum: ["Default", "Establishing Shot", "Master Shot", "Extreme Wide Shot (EWS/ELS)", "Very Wide Shot (VWS)", "Wide Shot (WS/LS)", "Full Shot (FS)", "Medium Wide Shot (MWS/American)", "Cowboy Shot (Mid-Thigh Up)", "Medium Shot (MS/Waist Up)", "Medium Close-Up (MCU/Chest Up)", "Close-Up (CU/Face)", "Choker Shot (Neck/Chin to Forehead)", "Extreme Close-Up (ECU/Features)", "Detail Shot / Insert", "Over-the-Shoulder (OTS)", "Point-of-View (POV)", "Cutaway Shot"], default: "Default", description: "Defines subject proximity and how much of the scene/context is visible."}, camera_angle: { title: "Camera Angle & Perspective", enum: ["Default / Eye-Level", "Shoulder Level", "High Angle (Looking Down)", "Low Angle (Looking Up)", "Dutch Angle / Canted Angle / Tilt", "Overhead / Bird's Eye View / Top Shot", "Ground Level Shot", "Worm's Eye View (Extreme Low)", "Hip Level", "Knee Level"], default: "Default / Eye-Level", description: "Camera's vertical position and tilt relative to the subject, affecting perspective and emotion."}, camera_movement: { title: "Camera Movement & Dynamics", enum: ["Default / Static Shot (No Movement)", "Pan (Left/Right)", "Whip Pan / Swish Pan", "Tilt (Up/Down)", "Whip Tilt", "Dolly (In/Out on Track/Wheels)", "Truck / Tracking / Following Shot (Parallel to Subject)", "Pedestal / Crane Shot (Vertical Lift)", "Boom Shot / Jib Arm (Arcing Vertical/Horizontal)", "Zoom (In/Out - Lens Magnification)", "Handheld Camera (Intentional Shake/Organic)", "Steadicam / Gimbal Shot (Smooth Floating)", "Arc Shot (Circles Subject)", "Dolly Zoom / Vertigo Effect / Zolly", "Drone Shot / Aerial Movement", "Reveal Shot (Gradual Unveiling)", "Random / Erratic Movement"], default: "Default / Static Shot (No Movement)", description: "Describes the physical motion or lens adjustment of the camera during the shot."}, lens_type_optical_effects: { title: "Lens Type & Optical Effects", enum: ["Default / Standard Lens (Natural Perspective)", "Wide-Angle Lens (Exaggerated Depth/Distortion)", "Telephoto Lens (Compressed Perspective/Shallow DoF)", "Prime Lens Look (Sharp, Fixed Focal Length)", "Anamorphic Lens Look (Oval Bokeh, Horizontal Flares)", "Fisheye Lens Effect (Extreme Barrel Distortion)", "Macro Lens Effect (Extreme Close-Up on Small Details)", "Tilt-Shift Effect (Miniature Look/Selective Focus Plane)", "Shallow Depth of Field (Blurred Background/Foreground)", "Deep Depth of Field (All in Focus)", "Rack Focus / Focus Pull (Shifting Focus Mid-Shot)", "Soft Focus / Diffusion Filter (Dreamy, Hazy)", "Creamy Bokeh (Smooth Out-of-Focus Areas)", "Swirly Bokeh", "Oval Bokeh (Anamorphic Specific)", "Lens Flare (Subtle/Natural)", "Lens Flare (Pronounced/Stylized)", "Lens Flare (Anamorphic Horizontal Blue/Orange)", "Starburst Lens Flare (Point Light Sources)", "Chromatic Aberration (Intentional Color Fringing)", "Lens Breathing Effect (Focal Shift During Focus)", "Split Diopter Effect (Two Focal Planes Sharp)"], default: "Default / Standard Lens (Natural Perspective)", description: "Choice of lens and how it shapes the image."}, lighting_style_atmosphere: { title: "Lighting Style & Atmosphere", enum: ["Default / Naturalistic Lighting", "Natural Light (Sunlight - Midday)", "Natural Light (Golden Hour / Magic Hour)", "Natural Light (Blue Hour / Twilight)", "Natural Light (Overcast / Diffused Daylight)", "Moonlight Effect / Night Lighting", "Candlelight / Firelight Effect", "Hard Light (Sharp, Defined Shadows)", "Soft Light (Diffused, Gentle Shadows)", "Flat Lighting (Minimal Shadows, Even Illumination)", "Three-Point Lighting (Key, Fill, Backlight)", "High-Key Lighting (Bright, Low Contrast, Cheerful)", "Low-Key Lighting (Dark, High Contrast, Dramatic)", "Chiaroscuro (Strong Light/Dark Contrast)", "Rembrandt Lighting (Triangular Light on Cheek)", "Rim Lighting / Backlighting (Outlines Subject)", "Silhouette Lighting (Subject Dark Against Bright BG)", "Warm Color Temperature (Oranges, Yellows)", "Cool Color Temperature (Blues, Cyans)", "Neon Lighting (Vibrant, Artificial Glow)", "Volumetric Lighting (Light Beams Visible, e.g., God Rays)", "Motivated Lighting (Source Appears Realistic to Scene)", "Practical Lights (Lamps, Fixtures in Scene)", "Spotlight Effect (Focused Beam)", "Kicker Light (Side/Rear Edge Light)", "Gobo / Patterned Light (Shadows/Light Shapes)", "Window Light (Natural or Simulated)", "Day for Night Effect (Simulating Night during Day)"], default: "Default / Naturalistic Lighting", description: "The quality, direction, color, and mood created by light sources and shadows."}, visual_style_medium_era: { title: "Visual Style, Medium & Era", enum: ["Default / Realistic", "Cinematic (Film-like Quality)", "Photorealistic (Highly Detailed, Real)", "Hyperrealistic (Exceedingly Real)", "Documentary (Observational / Vérité)", "Documentary (Expository / Interview-based)", "Film Noir (Dark, Shadowy B&W)", "Neo-Noir (Modern Film Noir)", "Found Footage (Handheld, Raw)", "Music Video (Stylized, Often Abstract)", "Commercial (Polished, Product-focused)", "Experimental / Art House", "Minimalist Style", "Action Sequence Style", "Surreal / Dreamlike", "Glitch Art / Datamosh", "Animation: 3D Render (Modern CGI)", "Animation: 2D Cel / Traditional", "Animation: Anime (Japanese Style)", "Animation: Cartoon (Western Style)", "Animation: Motion Graphics", "Animation: Stop Motion / Claymation", "Animation: Pixel Art", "Animation: Voxel Art", "Animation: Rotoscoped", "Animation: Hand-drawn Sketch Style", "Oil Painting Style", "Watercolor Painting Style", "Impressionistic Painting Style", "Charcoal Sketch Style", "Comic Book / Graphic Novel Style", "Matte Painting Look", "8mm Film Look (Grainy, Vintage)", "16mm Film Look (Grainy, Indie)", "35mm Film Look (Classic Cinema)", "Technicolor Look (Vibrant, Saturated 2-strip/3-strip)", "Kodachrome Look", "Ektachrome Look", "Fujifilm Stock Look", "VHS Aesthetic (80s/90s Tape)", "Betamax Look", "Early 2000s Digicam / MiniDV Look", "Vintage Newsreel (B&W, Aged)", "Archival Footage Look", "Sepia Tone Vintage", "1920s Silent Film Look", "1950s Cinema Look", "1960s Mod Style", "1970s Film Look (Gritty/Saturated)", "1980s Neon/Synthwave", "1990s Grunge Video", "Cyberpunk Aesthetic", "Steampunk Aesthetic", "Solarpunk Aesthetic", "Dieselpunk Aesthetic", "Gothic Aesthetic", "Fantasy Art Style", "Sci-Fi Concept Art Style", "Infrared / Thermal Look", "X-Ray Look", "Security Camera (CCTV) Look", "Music Video"], default: "Default / Realistic", description: "Defines the overall aesthetic appearance, artistic medium (e.g., animation, live action), and historical period influencing the visual elements."}, vfx_post_production: { title: "Visual Effects (VFX) & Post-Production Styles", enum: ["None / In-Camera Only", "Subtle CGI Integration", "Heavy CGI / VFX Driven", "Practical Effects Focus", "Rotoscoping (Animated Outlines)", "Motion Graphics Elements", "Particle Effects (Snow, Rain, Dust, Fog, Embers)", "Lens Flares (Added in Post)", "Light Leaks (Post Effect)", "Film Grain Overlay (Added Texture)", "Color Grading: Cinematic Teal & Orange", "Color Grading: Bleach Bypass", "Color Grading: Desaturated / Muted", "Color Grading: Vibrant / Highly Saturated", "Color Grading: Cross-Processed Look", "Glitches / Distortion (Digital Artifacts)", "VHS Tracking Lines / Analog Glitches", "Data Moshing / Databending", "Scanlines / Interlacing Effect", "Composite (Green Screen Keying Implied)", "Wire Removal (Implied Clean-up)", "Digital Makeup / Retouching", "Time-Lapse Photography Effect", "Slow Motion (Overcranked)", "Speed Ramping (Variable Speed)", "Motion Blur (Post-Production Effect)", "Light Streaks / Trails (Post)", "Digital Set Extension / Matte Painting Integration", "Screen Shake / Camera Jitter (Post)", "Bullet Time Effect", "Slit-Scan Effect", "Morphing Effect", "Explosions / Fire VFX", "Muzzle Flashes / Gunfire VFX", "Smoke / Atmospheric VFX"], default: "None / In-Camera Only", description: "Added visual manipulations, typically in post-production, or specific in-camera effect styles."}, color_palette_grading: { title: "Color Palette & Grading", enum: ["Default / Natural Colors", "Monochromatic (Single Color + Tints/Shades)", "Achromatic (Black, White, Grays)", "High Contrast Colors", "Low Contrast Colors", "Vibrant & Saturated Palette", "Desaturated / Muted Palette", "Pastel Color Palette", "Neon Color Palette", "Earthy Tones Palette", "Jewel Tones Palette", "Cool Color Dominant (Blues, Greens, Purples)", "Warm Color Dominant (Reds, Oranges, Yellows)", "Analogous Colors (Adjacent on Color Wheel)", "Complementary Colors (Opposite on Color Wheel)", "Triadic Colors (Evenly Spaced on Color Wheel)", "Split-Complementary Colors", "Teal and Orange Grading", "Bleach Bypass Look (Desaturated, High Contrast)", "Sepia Tone", "Two-Strip Technicolor Emulation", "Three-Strip Technicolor Emulation", "Cross-Processing Emulation"], default: "Default / Natural Colors", description: "Defines the dominant color scheme, color relationships, or specific color grading style."}, editing_pace_transitions: { title: "Editing Pace & Transitions (Implied)", enum: ["Default / Standard Pace", "Slow Pacing / Long Takes / Contemplative", "Fast Pacing / Quick Cuts / Energetic", "Montage Sequence (Series of Short Shots)", "Rhythmic Editing (To Music/Beat)", "Smooth Transitions (e.g., Standard Cuts, Soft Dissolves)", "Dynamic Transitions (e.g., Wipes, Graphic Matches, Hard Cuts)", "Jump Cuts (Disorienting, Noticeable)", "Match Cut (Visual/Conceptual Link)", "Split Screen Presentation", "Invisible Editing / Seamless Cuts"], default: "Default / Standard Pace", description: "Hints at the implied editing rhythm and style of transitions for the video's feel."}, subject_prominence: { title: "Subject Prominence & Focus", enum: ["Default / Balanced Focus", "Primary Subject Sharp / Background Soft (Bokeh)", "Deep Focus / All Elements in Focus", "Background / Environment as Main Subject", "Selective Focus on Detail", "Dynamic Focus Shift (Rack Focus Implied)"], default: "Default / Balanced Focus", description: "Directs attention and implies depth of field towards specific scene elements."}, custom_elements: { title: "Custom Elements / Keywords", type: "string", default: "", description: "Specific keywords, artist names, unique objects, or complex actions."} };

    function getAudioInstructionTextForPreamble(audioLevel) { switch (audioLevel) { case 'basic': return "Briefly mention key sound elements relevant to the scene (e.g., 'sound of rain', 'distant city hum', 'footsteps echoing')."; case 'detailed': return "Weave in rich and specific audio descriptions, covering environmental sounds, distinct sound effects, and, if appropriate, implied speech, character vocalizations, or dialogue that fits the scene's context. For example: 'The rhythmic clang of a hammer on hot metal, sparks hissing, accompanied by the blacksmith's heavy grunts. Distant marketplace chatter and the rumble of cartwheels on cobblestone provide a lively backdrop.' or 'A tense silence broken only by the chirping of crickets and the character's hushed whisper, \"They're close...\"'"; case 'none': default: return "Veo 3 will automatically attempt to generate relevant audio based on the visual description. No explicit audio cues are needed in the prompt unless specific sounds are critical."; } }
   const ARTISAN_PREAMBLE_CONFIG = {
    "Veo3_Artisan_Default": { displayName: "Generator", icon: "auto_awesome", getPreambleText: (params) => { const numPrompts = params.candidateCount || DEFAULT_CANDIDATE_COUNT; const audioLevel = params.audioPromptingLevel || DEFAULT_AUDIO_LEVEL; const audioInstructionForTemplate = getAudioInstructionTextForPreamble(audioLevel); const enableAudio = audioLevel && audioLevel !== 'none'; const userInput = "[USER_CONTENT_PLACEHOLDER]"; return `You are an expert AI assistant, a "Veo 2 Prompt Artisan & Scene Annotator," specializing in crafting exceptionally detailed, creative, and effective prompts for Google's Veo 2 video generation model. Your capabilities are akin to a sophisticated system trained to annotate vast quantities of video and image data with rich, multi-layered textual descriptions. You understand how to translate a core idea (from ${userInput}), potentially augmented by a reference image, into a descriptive narrative that Veo 2 can optimally interpret to generate compelling video.  Your primary goal is to generate ${numPrompts} distinct Veo 2 prompts based on the user's input. Each prompt must be a self-contained string, ready for direct use. You will strictly adhere to the official Google Veo 2 prompting guidelines and best practices.  **Core Prompting Methodology (Reflecting Veo 2's Optimal Input Structure & Training):** For each prompt, you will construct a descriptive narrative by elaborating on the following elements. Aim for a natural flow, as if describing a scene in detail:  1.  **Subject:** Clearly define the primary object(s), person(s), animal(s), or scenery. If an image is provided, the subject(s) are often derived or inspired by it. Describe key visual characteristics, attire, expressions, etc.     * *Annotator Insight:* Think about how you would tag the main entities in a video frame with their essential attributes.  2.  **Context:** Detail the background, environment, or setting where the subject is placed. Specify location, time of day, weather, and relevant environmental features.     * *Annotator Insight:* Capture the scene's broader setting, providing the necessary backdrop for the subject and action.  3.  **Action:** Describe precisely what the subject is doing (e.g., walking, running, interacting, transforming). If an image is provided and is static, the user's text will primarily define the action.     * *Annotator Insight:* Focus on dynamic verbs and the sequence of movements or events unfolding.  4.  **Style:** Define the overall visual aesthetic. This can range from general (e.g., "cinematic," "animated") to very specific (e.g., "film noir," "3D cartoon style render," "watercolor"). The style should be consistent with the subject and context. If an image is provided, its inherent style is a powerful influence.     * *Annotator Insight:* Identify and describe the artistic treatment, genre, or rendering technique that best characterizes the visual.  5.  **Camera Motion & Composition (Optional but Enhancing):** * **Camera Motion:** If relevant, specify how the camera is moving (e.g., "aerial view," "dolly in," "tracking shot," "pan left").     * **Composition:** Describe how the shot is framed (e.g., "wide shot," "close-up," "extreme close-up," "low-angle shot").     * *Annotator Insight:* Consider how a cinematographer would capture the scene for maximum impact or clarity. Describe the shot type and camera movement that would be used to create the annotation.  6.  **Ambiance (Optional but Enhancing):** Detail how color, light, and atmosphere contribute to the scene's mood and visual impact. (e.g., "cool blue tones," "warm golden hour light," "eerie green neon glow," "misty atmosphere").     * *Annotator Insight:* Describe the lighting conditions, color palette, and overall mood that define the scene's feel. ${enableAudio ? ` 7.  **Audio Elements (If Audio Prompting Enabled):** Naturally integrate descriptions of key audio components that would enhance the scene. This includes:     * **Sound Effects (SFX):** Specific sounds directly related to actions or objects (e.g., "the clatter of falling debris," "a gentle whoosh of wind," "the distinct click of a camera shutter").     * **Ambient Noise:** The background soundscape that defines the environment (e.g., "the distant chirping of crickets in a silent night," "the low murmur of a crowd in a bustling market," "the rhythmic lapping of waves on a shore").     * **Speech/Dialogue (Implied):** If characters are present and their interaction implies speech, describe its nature or tone (e.g., "a hushed, conspiratorial whisper," "an excited babble of voices," "a single, clear command"). Avoid writing full dialogue scripts.     * **Music (Implied Style/Mood):** Suggest the type or mood of music that would complement the scene, if appropriate (e.g., "a tense, orchestral score building suspense," "a light, whimsical flute melody," "heavy electronic beats for a cyberpunk setting").     * *Annotator Insight:* Think about the sounds you would hear if you were present in the scene. Describe them in a way that Veo 2 can interpret to co-generate appropriate audio alongside the visuals. Integrate these audio cues smoothly within the overall scene description rather than listing them separately. ` : ''} **Critical Guidelines for Prompt Generation:** * **Descriptive Language:** Employ rich adjectives and adverbs to paint a clear, vivid picture for Veo. Focus on visual elements ${enableAudio ? 'and auditory elements when appropriate' : ''}. * **Image Input Integration (If Provided):** * A user-provided image is a **primary visual anchor**.     * Thoroughly analyze the image for its subject matter, artistic style (e.g., photorealistic, painterly, abstract, cartoonish), color palette, composition, lighting, textures, and overall mood.     * **Crucially, synthesize these visual cues from the image with the user's textual description.** Your generated prompt must reflect a deep understanding and creative fusion of *both* inputs. For instance, if the image displays a specific art style, the prompt text must reinforce and elaborate on that style in relation to the described action and context.     * The image can inspire the setting, character appearance, specific objects, or the overall "feel" of the scene. The prompt describes how these elements interact or evolve. * **Specificity & Detail:** The more specific and detailed the prompt, the closer Veo's output will likely be to the desired result. Add layers of detail as if creating a comprehensive annotation. * **Facial Details:** If focusing on characters, consider using terms like "portrait" or describing expressions to enhance facial detail. * **Artistic Styles:** When referencing artistic styles or art movements, be precise. Consider keywords like "shallow depth of field," "movie still," "minimalistic," "surreal," "vintage," "futuristic," "double-exposure" if they align with the desired style. * **Negative Prompts – Implicit Exclusion:** * Follow the guideline: "Don't use instructive language or words like *no* or *don't*."     * Instead, **describe what you *do* want to see in a way that implicitly excludes what is undesired.** For example, if the user wants to avoid "urban background," describe a "vast, natural landscape" or "secluded forest clearing." If they want to avoid "blurry," describe it as "sharp, in-focus." * **Aspect Ratio & Duration:** If the user specifies an aspect ratio (e.g., "16:9 widescreen," "9:16 portrait") or a duration hint (e.g., "short clip," "time-lapse"), incorporate this naturally or as a concluding technical note if appropriate. * **Multiple Prompts (If Requested):** If generating more than one prompt ${numPrompts > 1 ? '(which you are)' : '(as you are generating one)'}, ensure each offers a distinct variation in detail, focus, perspective, or creative interpretation while still adhering to the core request.  **Output Format (Strictly Enforced):** You MUST output ONLY a valid JSON array of objects. Each object must have a single key: \`"prompt_text"\`, with the generated Veo 2 prompt as its string value. Do not include ANY other content, explanations, or introductory/concluding remarks outside this JSON array.  Example for ${numPrompts} prompt(s), strictly following the format: \`\`\`json [   {     "prompt_text": "A highly detailed Veo 2 prompt, narratively describing the subject, its action within a specific context, rendered in a particular style, potentially with camera and ambiance details ${enableAudio ? ', and integrated audio cues (SFX, ambient, speech hints, music style) ' : ''}synthesizing text and image inputs if provided."   }   ${numPrompts > 1 ? ',{\n    "prompt_text": "A second, distinct Veo 2 prompt, perhaps varying the level of detail, focusing on a different aspect of the scene, or offering an alternative creative interpretation based on the user\'s input and any provided image."\n  }' : ''}   ${numPrompts > 2 ? ',{\n    "prompt_text": "A third, distinct Veo 2 prompt, offering another unique angle or elaboration."\n  }' : ''}   ${numPrompts > 3 ? ',{\n    "prompt_text": "A fourth distinct prompt..."\n  }' : ''}   ${numPrompts > 4 ? ',{\n    "prompt_text": "And a fifth distinct prompt if requested."\n  }' : ''} ] \`\`\`  Focus on quality, adherence to Veo 2's capabilities, and maximizing creative potential by leveraging your understanding as both a prompt engineer and a sophisticated scene annotator.`;}, type: 'generation', requiresInputType: 'core_concept', promptPlaceholder: "Describe your vision for Veo 3...", showSchemaControls: true, showAdvancedSettingsLink: true, actionButtonText: "Generate Prompts", description: "The primary tool for generating a set of creative prompts based on your core idea, image, and detailed parameters."},
    "Veo3_Narrative_Arc": { displayName: "Story Arc", icon: "auto_stories", getPreambleText: (params) => { const audioLevel = params.audioPromptingLevel || DEFAULT_AUDIO_LEVEL; const audioInstruction = getAudioInstructionTextForPreamble(audioLevel); const enableAudio = audioLevel && audioLevel !== 'none'; const numPromptsForArc = params.candidateCount || 3; const userInput = "[USER_CONTENT_PLACEHOLDER]"; return `You are an expert AI assistant, a "Veo 2 Prompt Artisan & Scene Annotator." Your task is to take the user's provided Veo 2 prompt or concept (which describes a single shot or scene annotation, here: "${userInput}") and suggest ${numPromptsForArc} subsequent or related shots that could form a coherent visual sequence or mini-narrative, as if annotating a continuous piece of video. ${enableAudio ? `Audio prompting is enabled. For each suggested shot, include relevant audio descriptions (sound effects, ambient noise, speech characteristics, music style) integrated naturally into the prompt text.` : ''} The original prompt (current scene annotation or concept) is: "${userInput}"  For each suggested shot in the sequence: 1.  Generate a complete, detailed Veo 2 prompt text, serving as the "annotation" for that next segment of the scene. 2.  Ensure the suggested shot logically follows or complements the original prompt, detailing changes in subject focus, action progression, camera perspective, or environmental evolution. 3.  Maintain a consistent style and mood with the original prompt/annotation, unless a deliberate shift is part of the suggested sequence's narrative. 4.  Each prompt should be a comprehensive scene annotation ready for direct use with Veo 2.  Output ONLY a valid JSON object with the following structure: {   "original_prompt": "${userInput}",   "suggested_sequence_prompts": [     "Full prompt text for suggested shot/annotation 1...",     "Full prompt text for suggested shot/annotation 2...",     "Full prompt text for suggested shot/annotation 3 (if applicable)..."   ] } Do not include any other text, greetings, or explanations outside of this JSON structure. Provide ${numPromptsForArc} suggestions.`;}, type: 'generation', requiresInputType: 'theme_or_initial_idea', promptPlaceholder: "Enter a theme (e.g., 'a lost drone's journey home'), character goal, or initial scene idea...", showSchemaControls: true, showAdvancedSettingsLink: true, actionButtonText: "Generate Story Arc", description: "Generates a sequence of 3-5 scene prompts that form a coherent mini-story based on your theme or initial idea."},
    "Veo3_Character_Concept": { displayName: "Character Concept", icon: "person_search", getPreambleText: (params) => { const audioLevel = params.audioPromptingLevel || DEFAULT_AUDIO_LEVEL; const audioInstruction = getAudioInstructionTextForPreamble(audioLevel); const enableAudio = audioLevel && audioLevel !== 'none'; const numConcepts = params.candidateCount || 2; const userInput = "[USER_CONTENT_PLACEHOLDER]"; return `You are an AI assistant, a "Veo 2 Prompt Artisan & Scene Annotator," specializing in character creation for video prompts. The user has provided a basic character concept: "${userInput}". Your task is to brainstorm and generate detailed visual suggestions for this character, suitable for inclusion in a rich scene description (annotation) for Veo 2. (The user expects ${numConcepts} distinct concepts if applicable, but the primary output is one JSON as described below). Focus on attributes that would be visually prominent and contribute to a vivid character portrayal within a scene. ${enableAudio ? `Audio prompting is enabled. Also suggest vocal characteristics or sounds associated with the character.` : ''}  Categorize your suggestions as follows: -   **Key Appearance Details:** Specific physical features, clothing style and material, attire details, or unique visual characteristics an annotator would highlight. -   **Observable Personality Traits/Quirks:** Brief notes on their typical expressions, posture, mannerisms, or distinctive habits that would be visible in a scene. -   **Signature Visual Items/Accessories:** Objects, tools, or items strongly associated with the character that would be part of their visual annotation. ${enableAudio ? `-   **Suggested Vocal Characteristics/Sounds:** Ideas for the character's voice tone, pitch, speech patterns, or specific sounds they might make (e.g., "deep, gravelly voice," "high-pitched giggle," "robotic monotone," "a distinctive sigh").` : ''}  For each category, provide 2-4 distinct and evocative suggestions. Each suggestion should be a concise phrase or short description, ready to be woven into a larger Veo 2 scene annotation.  Output ONLY a valid JSON object with the following structure: {   "character_concept": "${userInput}",   "appearance_details": ["Detailed visual appearance suggestion 1 for annotation", "Suggestion 2...", "..."],   "personality_quirks": ["Observable personality/quirk suggestion 1 for annotation", "Suggestion 2...", "..."],   "signature_items_accessories": ["Visually distinct item/accessory suggestion 1 for annotation", "Suggestion 2...", "..."]   ${enableAudio ? ',"suggested_vocal_characteristics_sounds": ["Vocal idea 1", "Vocal idea 2...", "..."]' : ''} } Do not include any other text, greetings, or explanations outside of this JSON structure.`;}, type: 'generation', requiresInputType: 'character_archetype_or_details', promptPlaceholder: "Describe a character (e.g., 'elven archer with glowing tattoos', 'grumpy cyborg detective')...", showSchemaControls: true, showAdvancedSettingsLink: true, actionButtonText: "Generate Character Concepts", description: "Creates detailed visual and behavioral descriptions for a character, ideal for introductions or focus shots."},
    "Veo3_Environment_Design": { displayName: "Environment Design", icon: "forest", getPreambleText: (params) => { const audioLevel = params.audioPromptingLevel || DEFAULT_AUDIO_LEVEL; const audioInstruction = getAudioInstructionTextForPreamble(audioLevel); const enableAudio = audioLevel && audioLevel !== 'none'; const numPrompts = params.candidateCount || 2; const userInput = "[USER_CONTENT_PLACEHOLDER]"; return `You are an expert AI assistant, a "Veo 2 Prompt Artisan & Scene Annotator," specializing in crafting exceptionally detailed, creative, and effective prompts for Google's Veo 2 video generation model, with a focus on **ENVIRONMENT DESIGN** based on the user's concept: "${userInput}". Your capabilities are akin to a sophisticated system trained to annotate vast quantities of video and image data with rich, multi-layered textual descriptions. You understand how to translate a core idea for an **environment or setting**, potentially augmented by a reference image, into a descriptive narrative that Veo 2 can optimally interpret to generate compelling video of that environment.  Your primary goal is to generate ${numPrompts} distinct Veo 2 prompts based on the user's input describing an environment. Each prompt must be a self-contained string, ready for direct use. You will strictly adhere to the official Google Veo 2 prompting guidelines and best practices, emphasizing detailed descriptions of the **Context, Ambiance, and visual elements** of the environment.  **Core Prompting Methodology (Focus on Environment):** For each prompt, you will construct a descriptive narrative by elaborating on the following elements. Aim for a natural flow, as if describing a scene in detail:  1.  **Subject (Environment as Subject):** Clearly define the key aspects of the environment itself. Describe visual characteristics, architectural styles, natural formations, flora, fauna (if part of the environment's character), time of day, weather, etc. If an image is provided, the environment(s) are derived or inspired by it.     * *Annotator Insight:* Think about how you would tag the main features and attributes of the environment in a video frame.  2.  **Context (Overarching World/Setting):** If relevant, detail the broader world or situation this environment exists within. This provides the necessary backdrop.     * *Annotator Insight:* Capture the scene's larger setting if it influences the specific environment.  3.  **Action (Implied or Potential):** Describe what might be happening or could happen within this environment, or its inherent 'action' (e.g., "a windswept desert," "a bustling futuristic city street").     * *Annotator Insight:* Focus on dynamic environmental elements or potential interactions.  4.  **Style:** Define the overall visual aesthetic of the environment. This can range from general (e.g., "photorealistic," "fantasy concept art") to very specific (e.g., "gloomy Giger-esque biomechanical interior," "impressionistic watercolor landscape"). The style should be consistent with the environment's description. If an image is provided, its inherent style is a powerful influence.     * *Annotator Insight:* Identify and describe the artistic treatment that best characterizes the environment.  5.  **Camera Motion & Composition (Optional but Enhancing):** * **Camera Motion:** If relevant, specify how the camera might move to showcase the environment (e.g., "sweeping panoramic shot," "slow aerial descent," "exploratory tracking shot").     * **Composition:** Describe how a shot of the environment might be framed (e.g., "establishing wide shot," "detail shot of a texture," "low-angle shot emphasizing scale").     * *Annotator Insight:* Consider how a cinematographer would capture the environment for maximum impact or clarity.  6.  **Ambiance (Crucial for Environment):** Detail how color, light, atmosphere, and sensory details contribute to the environment's mood and visual impact. (e.g., "cool blue tones and deep shadows creating a mysterious feel," "warm golden hour light illuminating floating dust motes," "oppressive red emergency lighting in a derelict spaceship corridor," "a thick, misty atmosphere obscuring distant shapes").     * *Annotator Insight:* Describe the lighting conditions, color palette, and overall mood that define the environment's feel. ${enableAudio ? ` 7.  **Audio Elements (If Audio Prompting Enabled):** Naturally integrate descriptions of key audio components that would characterize the environment. This includes:     * **Sound Effects (SFX):** Specific sounds directly related to environmental features (e.g., "the rustling of leaves in a dense forest," "the distant roar of a waterfall," "the hum of alien machinery").     * **Ambient Noise:** The background soundscape that defines the environment (e.g., "the gentle lapping of waves on a tropical beach," "the cacophony of sounds in a medieval market," "the eerie silence of an abandoned space station punctuated by metallic groans").     * *Annotator Insight:* Think about the sounds you would hear if you were present in the environment. Describe them in a way that Veo 2 can interpret. ` : ''} **Critical Guidelines for Prompt Generation:** (Follow general Veo 2 guidelines, focusing on visual and environmental details). **Output Format (Strictly Enforced):** You MUST output ONLY a valid JSON array of objects. Each object must have a single key: \`"prompt_text"\`.  Example for ${numPrompts} prompt(s): \`\`\`json [   {     "prompt_text": "A highly detailed Veo 2 prompt describing an environment based on user concept: ${userInput}"   }   ${numPrompts > 1 ? ',{\n    "prompt_text": "A second, distinct Veo 2 environment prompt."\n  }' : ''} ] \`\`\`  Focus on quality, adherence to Veo 2's capabilities, and maximizing creative potential for environment design.`;}, type: 'generation', requiresInputType: 'environment_concept_or_keywords', promptPlaceholder: "Describe an environment (e.g., 'abandoned space station', 'magical library')...", showSchemaControls: true, showAdvancedSettingsLink: true, actionButtonText: "Generate Environments", description: "Crafts immersive prompts for locations or establishing shots, detailing atmosphere, key features, and sensory details."},
    "Veo3_Scene_Extender": { displayName: "Scene Extender", icon: "expand_content", getPreambleText: (params) => { const al = params.audioPromptingLevel || DEFAULT_AUDIO_LEVEL; const ai = getAudioInstructionTextForPreamble(al); const enableAudio = al && al !== 'none'; const originalPrompt = "[USER_CONTENT_PLACEHOLDER]"; return `You are an expert AI assistant, a "Veo 2 Prompt Artisan & Scene Annotator." Your task is to take the user's provided Veo 2 prompt ("${originalPrompt}") and elaborate upon it, transforming it into a more detailed, descriptive, and evocative scene description (annotation) for video generation. Focus on enriching the existing concepts by adding layers of visual and contextual detail, as if meticulously annotating a complex scene. ${enableAudio ? `Audio prompting is enabled, so also enhance or add relevant audio descriptions (sound effects, ambient noise, speech characteristics, music style) that fit the scene and are integrated naturally.` : ''} The original prompt is: "${originalPrompt}"  Please provide 1 to 2 elaborated versions of this prompt. Each elaborated prompt should: 1.  Significantly enhance details about the Subject, Action, Context, and Style, as a detailed scene annotation would. 2.  If appropriate, suggest or refine Camera work (angles, movement) and Ambiance (lighting, atmosphere) to create a richer visual narrative. 3.  Maintain the core intent of the original prompt while layering in descriptive richness. 4.  Be ready for direct use with Veo 2, reflecting the qualities of a comprehensive scene annotation. 5.  Adhere to Veo 2 prompting best practices.  Output ONLY a valid JSON object with the following structure: {   "original_prompt": "${originalPrompt}",   "elaborated_prompts": [     "First elaborated version, now a richer scene annotation...",     "Second elaborated version, perhaps exploring different descriptive facets (if applicable)..."   ] } Do not include any other text, greetings, or explanations outside of this JSON structure. If the original prompt is already very detailed, you might return only one significantly enhanced version or a minor refinement focusing on annotative depth.`;}, type: 'extension', requiresInputType: 'scene_to_extend', promptPlaceholder: "Enter scene description to extend...", showSchemaControls: true, showAdvancedSettingsLink: true, actionButtonText: "Extend Scene", description: "Elaborates on an existing scene or idea, adding detail, sensory information, and optimizing for Veo 3."},
    "Veo3_Critique_Enhance": { displayName: "Prompt Critiquer", icon: "rate_review", getPreambleText: (params) => { const audioLevel = params.audioPromptingLevel || DEFAULT_AUDIO_LEVEL; /* Not used directly in Veo 2 version, enableAudio is derived */ const enableAudio = audioLevel && audioLevel !== 'none'; const promptToCritique = "[USER_CONTENT_PLACEHOLDER]"; return `You are an expert AI assistant, a "Veo 2 Prompt Artisan & Scene Annotator," specializing in crafting and refining prompts for Google's Veo 2 video generation model. Your task is to critique the provided Veo 2 prompt ("${promptToCritique}") and offer actionable suggestions for improvement, viewing the prompt as a potential scene description.  Analyze the prompt based on its effectiveness as a detailed and evocative scene annotation for Veo 2, considering: 1.  **Subject Clarity & Detail:** Is the primary subject (object, person, animal, scenery) clearly defined with sufficient visual detail, as a good annotation would capture? 2.  **Contextual Richness:** Is the background/environment described well enough to ground the scene? 3.  **Action Specificity:** Is the subject's action (what it's doing) precise and visually imaginable? 4.  **Style Coherence:** Is the visual style effectively conveyed and consistent with the described scene? 5.  **Camera & Composition (if any):** Are camera instructions clear and do they enhance the potential scene description? 6.  **Ambiance & Atmosphere:** Is the mood, lighting, and overall atmosphere described in a way that enriches the scene? ${enableAudio ? `7.  **Audio Description Effectiveness:** How well does the prompt describe or imply relevant sound effects, ambient noise, speech characteristics, or music? Are audio cues integrated naturally and do they enhance the scene?` : ''} 8.  **Veo 2 Best Practices & Annotative Quality:** Does the prompt align with Veo 2 guidelines and does it read like a high-quality, detailed annotation ready for video generation? 9.  **Potential for Compelling Video:** How likely is this prompt, as a scene description, to generate an engaging and visually interesting video clip?  Based on your analysis, provide: 1.  A concise overall critique (max 2-3 sentences) focusing on its strength as a scene annotation. 2.  A list of 2-3 specific, actionable suggestions for enhancement. Each suggestion MUST be a complete, self-contained, and improved version of the original prompt, refined to be a more effective scene description/annotation for Veo 2. ${enableAudio ? 'If audio prompting is enabled, ensure suggestions also consider or improve audio elements.' : ''}  Output ONLY a valid JSON object with the following structure: {   "critique": "Your overall critique of the prompt as a scene annotation.",   "suggested_enhancements": [     "Full suggested prompt text 1, enhanced as a richer scene annotation.",     "Full suggested prompt text 2, further enhanced for Veo 2.",     "Full suggested prompt text 3 (if distinct enough)."   ] }  Do not include any other text, greetings, or explanations outside of this JSON structure.  The prompt to critique is: "${promptToCritique}"`;}, type: 'critique_enhance', requiresInputType: 'prompt_to_critique', promptPlaceholder: "Paste Veo 3 prompt to critique...", showSchemaControls: false, showAdvancedSettingsLink: false, actionButtonText: "Critique & Enhance", description: "Analyzes your existing prompt, provides feedback, and suggests an enhanced version."},
    "Veo3_Infer_Parameters": { displayName: "Visual Suggester", icon: "auto_fix_high", getPreambleText: (params) => { const vs = VEO_STYLES.filter(s=>s).join('", "'); const va = VEO_CAMERA_ANGLES.filter(s=>s).join('", "'); const vm = VEO_CAMERA_MOVEMENTS.filter(s=>s).join('", "'); const vl = VEO_LIGHTING_CONDITIONS.filter(s=>s).join('", "'); const audioLevel = params.audioPromptingLevel || DEFAULT_AUDIO_LEVEL; const enableAudio = audioLevel && audioLevel !== 'none'; const userInputText = "[USER_CONTENT_PLACEHOLDER]"; return `You are an expert AI assistant, a "Veo 2 Prompt Analyst." Your task is to analyze the following text provided by the user ("${userInputText}") and infer potential Veo 2 prompting parameters that would best achieve the described visual.  Based on the text, identify and suggest:  1.  **Key Subject(s) & Actions:** What are the main elements and what are they doing? 2.  **Likely Context/Setting:** Where and when is this taking place? 3.  **Implied Visual Style:** What artistic or cinematic style is suggested (e.g., photorealistic, anime, watercolor, film noir, etc.)? Do not limit yourself to a predefined list. 4.  **Potential Camera Work:** Any implied camera angles or movements (e.g., close-up, wide shot, tracking shot)? Do not limit yourself to a predefined list. 5.  **Dominant Ambiance/Mood:** What is the overall feeling, lighting (e.g. golden hour, moody, neon), and color palette suggested? Do not limit yourself to a predefined list. ${enableAudio ? `6.  **Suggested Audio Elements:** What kinds of sounds (SFX, ambient, music style) would fit?` : ''}  Structure your output as a JSON object containing these inferred elements, which can then be used to build a full Veo 2 prompt. For example:  \`\`\`json {   "inferred_subject": "A lone astronaut",   "inferred_action": "walking on a desolate Mars-like planet",   "inferred_context": "Barren red landscape, distant twin moons in a purple sky",   "inferred_style": "Cinematic, photorealistic with a touch of sci-fi concept art",   "inferred_camera": "Medium tracking shot from a low angle",   "inferred_ambiance": "Eerie silence, cool tones, long shadows",   "inferred_audio_elements": "Radio static, crunching footsteps, low synthesized hum" } \`\`\`  Provide a single, comprehensive JSON object. Do not refer to predefined lists like "${vs}", "${va}", etc., in your response; use your expert knowledge to suggest suitable terms.`; }, type: 'utility_infer', requiresInputType: 'core_concept_for_inference', promptPlaceholder: "Enter concept to infer parameters for...", showSchemaControls: false, showAdvancedSettingsLink: false, actionButtonText: "Suggest Visuals", description: "Analyzes your concept (text/image) and suggests suitable Style, Camera Angle, Movement, and Lighting."},
    "Veo3_Surprise_Me": { displayName: "Surprise Me!", icon: "casino", getPreambleText: (params) => { const vs = VEO_STYLES.filter(s=>s).join('", "'); const audioLevel = params.audioPromptingLevel || DEFAULT_AUDIO_LEVEL; const enableAudio = audioLevel && audioLevel !== 'none'; const numPrompts = 1; /* Surprise me usually gives one strong concept */ const userInput = "[USER_CONTENT_PLACEHOLDER]"; return `You are an expert AI assistant, a "Veo 2 Prompt Artisan & Scene Annotator," specializing in crafting **highly creative and unexpected** prompts for Google's Veo 2 video generation model. Your primary goal is to generate ${numPrompts} distinct, imaginative, and visually interesting Veo 2 prompt. If the user provides minimal input like "surprise me" (which would be in "${userInput}"), generate a truly novel concept. If they provide a seed idea in "${userInput}", use that as a starting point for a surprising twist.  The prompt should be a highly detailed scene description ready for Veo 2. Include: Subject, Action, Context, Style, and optionally Camera/Ambiance. ${enableAudio ? `Integrate surprising or fitting Audio Elements if enabled.` : ''} Do not merely output a short concept and style; output a full, usable prompt.  **Output Format (Strictly Enforced):** You MUST output ONLY a valid JSON array of objects. Each object must have a single key: \`"prompt_text"\`.  Example for ${numPrompts} prompt: \`\`\`json [   {     "prompt_text": "A highly creative, surprising, and detailed Veo 2 prompt (e.g., A time-traveling sloth attempts to play a futuristic stock market, data streams visible in its reflective helmet, energetic synthwave music, close-up on its determined, slow-moving face, neon-lit cyberpunk city background)."   } ] \`\`\` `; }, type: 'utility_surprise', requiresInputType: 'optional_seed_for_surprise', promptPlaceholder: "Optional: Keyword for surprise or leave blank...", showSchemaControls: false, showAdvancedSettingsLink: false, actionButtonText: "Surprise Me!", description: "Generates a random, creative video concept along with suggested visual parameters. Optionally use a keyword as a seed."},
    "Tool_Brainstorm_Elements": { displayName: "AV Brainstormer", icon: "emoji_objects", getPreambleText: (params) => { const audioLevel = params.audioPromptingLevel || DEFAULT_AUDIO_LEVEL; const enableAudio = audioLevel && audioLevel !== 'none'; const theme = "[USER_CONTENT_PLACEHOLDER]"; return `You are a creative AI assistant, a "Veo 2 Prompt Artisan & Scene Annotator," specializing in brainstorming video concepts. The user has provided a theme: "${theme}". Your task is to generate a list of related ideas, suitable for developing into detailed scene descriptions (annotations) for Veo 2. Categorize these ideas as follows:  -   **Potential Subjects/Characters:** Entities that could be the focus of a scene annotation. -   **Evocative Settings/Environments:** Backgrounds that would provide rich context for a scene annotation. -   **Key Visual Elements/Props:** Specific objects or motifs that would add detail and interest to a scene annotation. -   **Descriptive Moods/Styles/Keywords:** Terms that would help define the visual and atmospheric qualities of a scene annotation. ${enableAudio ? `-   **Suggested Audio Elements or Moods:** Ideas for sound effects, ambient noise, music styles, or overall audio atmosphere that would complement the theme.` : ''}  For each category, provide 2-4 distinct and evocative suggestions. Each suggestion should be a concise phrase or short description, primed for expansion into a full Veo 2 prompt. Think about what elements would make a scene visually ${enableAudio ? 'and audibly ' : ''}compelling and "annotatable."  Output ONLY a valid JSON object with the following structure: {   "theme_name": "${theme}",   "suggested_subjects_characters": ["Subject/Character idea 1 for scene annotation", "Subject/Character idea 2...", "..."],   "suggested_settings_environments": ["Setting/Environment idea 1 for scene annotation", "Setting/Environment idea 2...", "..."],   "suggested_key_objects_props": ["Key visual/prop idea 1 for scene annotation", "Key visual/prop idea 2...", "..."],   "suggested_mood_keywords_styles": ["Mood/Style descriptor 1 for scene annotation", "Mood/Style descriptor 2...", "..."]   ${enableAudio ? ',"suggested_audio_elements_moods": ["Audio idea 1", "Audio idea 2...", "..."]' : ''} } Do not include any other text, greetings, or explanations outside of this JSON structure.`;}, type: 'utility_tool', requiresInputType: 'core_concept_for_brainstorm', promptPlaceholder: "Concept to brainstorm elements for...", showSchemaControls: false, showAdvancedSettingsLink: false, actionButtonText: "Brainstorm Elements", description: "Brainstorms a list of specific visual and auditory elements based on your core concept."},
    "Tool_Suggest_Story_Arc_Old": { displayName: "Story Arc Suggester (Old)", icon: "dynamic_feed", getPreambleText: (params) => { const audioLevel = params.audioPromptingLevel || DEFAULT_AUDIO_LEVEL; const enableAudio = audioLevel && audioLevel !== 'none'; const numPromptsForArc = params.candidateCount || 3; // Using candidateCount for number of scenes
        const originalPrompt = "[USER_CONTENT_PLACEHOLDER]"; return `You are an expert AI assistant, a "Veo 2 Prompt Artisan & Scene Annotator." Your task is to take the user's provided Veo 2 prompt or concept (which describes a single shot or scene annotation, here: "${originalPrompt}") and suggest ${numPromptsForArc} subsequent or related shots that could form a coherent visual sequence or mini-narrative, as if annotating a continuous piece of video. ${enableAudio ? `Audio prompting is enabled. For each suggested shot, include relevant audio descriptions (sound effects, ambient noise, speech characteristics, music style) integrated naturally into the prompt text.` : ''} The original prompt (current scene annotation or concept) is: "${originalPrompt}"  For each suggested shot in the sequence: 1.  Generate a complete, detailed Veo 2 prompt text, serving as the "annotation" for that next segment of the scene. 2.  Ensure the suggested shot logically follows or complements the original prompt, detailing changes in subject focus, action progression, camera perspective, or environmental evolution. 3.  Maintain a consistent style and mood with the original prompt/annotation, unless a deliberate shift is part of the suggested sequence's narrative. 4.  Each prompt should be a comprehensive scene annotation ready for direct use with Veo 2.  Output ONLY a valid JSON object with the following structure: {   "original_prompt": "${originalPrompt}",   "suggested_sequence_prompts": [     "Full prompt text for suggested shot/annotation 1...",     "Full prompt text for suggested shot/annotation 2...",     "Full prompt text for suggested shot/annotation 3 (if applicable)..."   ] } Do not include any other text, greetings, or explanations outside of this JSON structure. Provide ${numPromptsForArc} suggestions.`;}, type: 'utility_tool', requiresInputType: 'broader_idea_for_arc', promptPlaceholder: "Broader idea for story arc...", showSchemaControls: false, showAdvancedSettingsLink: false, actionButtonText: "Suggest Arc (Old)", description: "Suggests a short sequence of 2-3 related scene prompts to form a mini-story arc from a broader idea."},
    "Tool_Explain_Parameter": { displayName: "Parameter Explainer", icon: "contact_support", getPreambleText: (params) => { const parameterToExplain = "[USER_CONTENT_PLACEHOLDER]"; return `You are an expert on Google's Veo 2 video generation model and cinematic techniques. The user is asking a question about a Veo 2 parameter, a visual concept, or seek advice on achieving a certain effect related to "${parameterToExplain}". Provide a clear, concise, and helpful explanation or suggestion. If explaining a parameter (e.g., 'Dutch Angle'), describe what it is and its typical use or effect in Veo 2 prompting. If asked for advice (e.g., 'Best lighting for horror?'), provide actionable suggestions for Veo 2 prompts and brief reasoning. Focus on being helpful and informative for someone learning to write effective Veo 2 prompts. Do not generate a Veo 2 prompt itself unless it's a small example illustrating your explanation. Output your explanation as plain text.`;}, type: 'utility_tool', requiresInputType: 'parameter_or_question', promptPlaceholder: "e.g., 'Explain Dutch Angle' or 'Best lighting for horror?'", showSchemaControls: false, showAdvancedSettingsLink: false, actionButtonText: "Explain", description: "Explains Veo 3 parameters, visual concepts, or provides advice on achieving specific effects." }
};
    // --- Initial Application State ---
    const initialAdvancedSettings = { aspectRatio: VEO_ASPECT_RATIOS_VALUES[0], durationHint: VEO_DURATION_HINTS[0] };
    for (const key in SCHEMA_INPUTS) { initialAdvancedSettings[key] = SCHEMA_INPUTS[key].default || ''; }

    const appState = {
        isLoading: false, currentActionMessage: '', error: null,
        promptParams: {
            description: '', negativePrompt: '',
            candidateCount: DEFAULT_CANDIDATE_COUNT,
            artisanMode: GM_getValue(STORAGE_KEYS.ACTIVE_TOOL_ID) || Object.keys(ARTISAN_PREAMBLE_CONFIG)[0],
            audioPromptingLevel: GM_getValue(STORAGE_KEYS.SELECTED_AUDIO_LEVEL) || DEFAULT_AUDIO_LEVEL,
            style: GM_getValue(STORAGE_KEYS.SELECTED_STYLE) || DEFAULT_STYLE_KEY,
            advancedSettings: { ...initialAdvancedSettings },
            uploadedImage: null,
        },
        generatedPrompts: [], history: [], favorites: [],
        ui: {
            isMainPanelVisible: false, isHistoryPanelVisible: false, isFavoritesPanelVisible: false,
            isAdvancedSettingsModalVisible: false, isFabMenuOpen: false,
            activeToolId: GM_getValue(STORAGE_KEYS.ACTIVE_TOOL_ID) || Object.keys(ARTISAN_PREAMBLE_CONFIG)[0],
        },
    };

    // --- MODULES ---
    const Utils = {}; const Storage = {}; const API = {}; const UI = {}; const Handlers = {};

    // --- UTILITY FUNCTIONS ---
    Utils.debounce = (func, delay) => { let timeoutId; return (...args) => { clearTimeout(timeoutId); timeoutId = setTimeout(() => func.apply(this, args), delay); }; };
    Utils.generateId = () => `id-${Date.now()}-${Math.random().toString(36).substring(2, 9)}`;
    Utils.buildUserContentString = (params, imageInfoString) => {
        let userContent = `Core Concept/Input: "${params.description || (imageInfoString ? "(See image reference)" : "(No textual description provided)")}"`;
        if (imageInfoString) userContent += `\nImage Reference: ${imageInfoString}`;
        const currentToolConfig = ARTISAN_PREAMBLE_CONFIG[appState.ui.activeToolId];
        if (currentToolConfig && currentToolConfig.showSchemaControls) {
            if (params.style && params.style !== DEFAULT_STYLE_KEY) userContent += `\nDesired Visual Style: "${params.style}"`;
            const advancedSelections = [];
            for (const key in params.advancedSettings) {
                const value = params.advancedSettings[key]; const schemaDef = SCHEMA_INPUTS[key];
                const veoSpecificKeyDisplay = { aspectRatio: "Aspect Ratio", durationHint: "Duration Hint" };
                if (value && typeof value === 'string' && value.trim() !== "") {
                    if (schemaDef && value !== schemaDef.default) advancedSelections.push(key==='custom_elements' ? `Custom: ${value.trim()}` : `${schemaDef.title}: ${value}`);
                    else if (veoSpecificKeyDisplay[key] && value !== (key==='aspectRatio'?VEO_ASPECT_RATIOS_VALUES[0]:VEO_DURATION_HINTS[0])) advancedSelections.push(`${veoSpecificKeyDisplay[key]}: ${value}`);
                }
            }
            if (advancedSelections.length > 0) userContent += `\nDetailed Parameters: ${advancedSelections.join('; ')}.`;
        }
        if (params.negativePrompt && params.negativePrompt.trim() !== "") userContent += `\nNegative Keywords (Avoid): "${params.negativePrompt.trim()}"`;
        return userContent;
    };

    // --- STORAGE SERVICE ---
    Storage.loadHistory = () => JSON.parse(GM_getValue(STORAGE_KEYS.HISTORY, '[]'));
    Storage.saveHistory = (history) => GM_setValue(STORAGE_KEYS.HISTORY, JSON.stringify(history.slice(0, MAX_HISTORY_ITEMS)));
    Storage.loadFavorites = () => JSON.parse(GM_getValue(STORAGE_KEYS.FAVORITES, '[]'));
    Storage.saveFavorites = (favorites) => GM_setValue(STORAGE_KEYS.FAVORITES, JSON.stringify(favorites.slice(0, MAX_FAVORITES_ITEMS)));
    Storage.loadEnhancerPresets = () => JSON.parse(GM_getValue(STORAGE_KEYS.ENHANCER_PRESETS, '{}'));
    Storage.saveEnhancerPresets = (presets) => GM_setValue(STORAGE_KEYS.ENHANCER_PRESETS, JSON.stringify(presets));


    // --- API SERVICE ---
    API.gmFetch = (url, options) => new Promise((resolve, reject) => { GM_xmlhttpRequest({ method: options.method || "GET", url, headers: options.headers || {}, data: options.body, responseType: "json", onload: r => (r.status>=200&&r.status<300)?resolve({ok:!0,status:r.status,json:()=>Promise.resolve(r.response),text:()=>Promise.resolve(r.responseText)}):resolve({ok:!1,status:r.status,json:()=>Promise.resolve(r.response||{}),text:()=>Promise.resolve(r.responseText)}), onerror:r=>reject(new Error(r.statusText||"Network error")), ontimeout:()=>reject(new Error("timeout")), onabort:()=>reject(new Error("aborted"))});});
    API.generatePrompts = async () => {
        appState.isLoading = true; appState.error = null; appState.generatedPrompts = [];
        UI.renderAppStatus();
        const activeToolId = appState.ui.activeToolId;
        const modeConfig = ARTISAN_PREAMBLE_CONFIG[activeToolId];
        if (!modeConfig) { appState.error = "Invalid Tool selected."; appState.isLoading = false; UI.render(); return; }

        appState.promptParams.artisanMode = activeToolId;

        let preambleBaseText = modeConfig.getPreambleText({ candidateCount: appState.promptParams.candidateCount, audioPromptingLevel: appState.promptParams.audioPromptingLevel });
        let imageInfoString = "";
        if (appState.promptParams.uploadedImage && (modeConfig.type === 'generation' || modeConfig.type === 'extension' || modeConfig.type === 'utility_infer')) {
            imageInfoString = `[Image Provided: ${appState.promptParams.uploadedImage.name}, Type: ${appState.promptParams.uploadedImage.mimeType}] - Visual style, subject, and mood should be HEAVILY influenced by this image.`;
        }
        const userContentToInject = Utils.buildUserContentString(appState.promptParams, imageInfoString);
        const finalPromptForApi = preambleBaseText.replace("[USER_CONTENT_PLACEHOLDER]", userContentToInject);

        const payload = {
            prompt: finalPromptForApi,
            sessionId: `artisan-session-${Utils.generateId()}`,
            image: (modeConfig.type === 'generation' || modeConfig.type === 'extension' || modeConfig.type === 'utility_infer') && appState.promptParams.uploadedImage ? appState.promptParams.uploadedImage.b64 : "",
            candidateCount: (modeConfig.type === 'generation' || modeConfig.type === 'extension') ? (parseInt(appState.promptParams.candidateCount, 10) || DEFAULT_CANDIDATE_COUNT) : 1,
            preamble: activeToolId // This is used by the endpoint per user's existing setup.
        };
        console.log(`Artisan (${activeToolId}): Sending to API. Preview (first 300): ${finalPromptForApi.substring(0,300)}`);
        appState.currentActionMessage = `Artisan is working (${modeConfig.displayName})...`;
        UI.renderAppStatus();

        try {
            const response = await API.gmFetch(API_ENDPOINT, { method: 'POST', headers: { 'Content-Type': 'application/json', 'Accept': '*/*' }, body: JSON.stringify({ json: payload }) });
            if (!response.ok) { let errorData = "API request failed."; try { errorData = await response.text(); if (errorData.trim().startsWith('{')) errorData = JSON.stringify(JSON.parse(errorData),null,2); } catch (_) {} throw new Error(`API Error ${response.status}: ${errorData}`); }
            const result = await response.json();
            const candidates = result?.result?.data?.json?.result?.candidates;
            if (candidates && Array.isArray(candidates)) { appState.generatedPrompts = candidates.map(c => c?.output).filter(text => typeof text === 'string' && text.trim() !== "").map(text => ({ id: Utils.generateId(), text: text.trim() })); }
            else { const singleOutput = result?.result?.data?.json?.result?.output; if (typeof singleOutput === 'string' && singleOutput.trim() !== "") appState.generatedPrompts = [{ id: Utils.generateId(), text: singleOutput.trim() }]; else if (appState.generatedPrompts.length === 0) throw new Error('No valid prompt outputs found in API response.');}
            if (appState.generatedPrompts.length === 0 && (!candidates || candidates.length === 0)) throw new Error('API returned no candidates or usable output.');

            if (activeToolId === "Veo3_Infer_Parameters" && appState.generatedPrompts.length > 0) Handlers.parseAndApplyInferredParameters(appState.generatedPrompts[0].text);
            else if (activeToolId === "Veo3_Surprise_Me" && appState.generatedPrompts.length > 0) Handlers.parseAndApplySurpriseMe(appState.generatedPrompts[0].text);

            const historyEntry = { id: Utils.generateId(), timestamp: Date.now(), params: { description: appState.promptParams.description, artisanMode: activeToolId, negativePrompt: appState.promptParams.negativePrompt, candidateCount: appState.promptParams.candidateCount, audioPromptingLevel: appState.promptParams.audioPromptingLevel, style: appState.promptParams.style, advancedSettings: JSON.parse(JSON.stringify(appState.promptParams.advancedSettings)), uploadedImage: appState.promptParams.uploadedImage ? { name: appState.promptParams.uploadedImage.name, mimeType: appState.promptParams.uploadedImage.mimeType } : null }, prompts: JSON.parse(JSON.stringify(appState.generatedPrompts)), modeUsed: activeToolId };
            appState.history = [historyEntry, ...Storage.loadHistory()]; Storage.saveHistory(appState.history);
        } catch (err) { console.error("Artisan: Error generating prompts:", err); appState.error = err.message; }
        finally { appState.isLoading = false; appState.currentActionMessage = ''; UI.render(); }
    };

    // --- UI RENDERING & DOM MANIPULATION ---
    Object.assign(UI, {
        elements: {
            rootContainer: null, fabContainer: null, mainFab: null, historyFab: null, favoritesFab: null,
            mainPanel: null, mainPanelHeaderElement: null, tabNavContainer: null, tabContentContainer: null, mainPanelFooter: null,
            promptInput: null, negativePromptInput: null, candidateCountSelect: null,
            audioLevelSelect: null, styleSelect: null, imageUploadInput: null, imagePreview: null,
            advancedSettingsLinkSection: null, livePreviewArea: null, resultsContainer: null,
            advancedSettingsModal: null, historyModal: null, favoritesModal: null, globalStatusArea: null,
            confirmationModal: null, promptModal: null,
            advancedSettingsInputsMap: {}, advancedSettingsContainer: null,
        },
        createIcon: (iconName) => { const span = document.createElement('span'); span.className = 'material-symbols-outlined'; span.textContent = (typeof iconName === 'string' && iconName.trim() !== '') ? iconName.trim() : 'texture'; span.setAttribute('aria-hidden', 'true'); return span; },
        createButton: ({ text, icon, className, onClick, title, disabled = false }) => { const btn = document.createElement('button'); const baseClassName = 'artisan-button'; btn.className = className ? `${baseClassName} ${className}` : baseClassName; let iconElement = null; if (typeof icon === 'string' && icon.trim() !== '') { iconElement = UI.createIcon(icon.trim()); if (iconElement instanceof Node) btn.appendChild(iconElement); else { console.error("UI.createIcon !Node for icon:", icon); btn.appendChild(document.createTextNode(`[${icon || 'icon'}]`)); } } if (typeof text === 'string' && text.trim() !== '') { const textNode = document.createTextNode(text.trim()); btn.appendChild(textNode); if (iconElement && iconElement.parentNode === btn) { iconElement.style.marginRight = "0.5em"; iconElement.style.marginLeft = "-0.25em"; } } else if (iconElement) { btn.classList.add('icon-only'); } if (typeof onClick === 'function') btn.onclick = onClick; if (typeof title === 'string') btn.title = title; btn.disabled = !!disabled; return btn; },
        createModalHeader: (titleText, onCloseCallback) => { const headerDiv = document.createElement('div'); headerDiv.className = 'artisan-modal-header'; const titleElement = document.createElement('h2'); titleElement.className = 'artisan-modal-title'; titleElement.id = `modal-title-${Utils.generateId()}`; titleElement.textContent = (typeof titleText === 'string') ? titleText : 'Modal Title'; headerDiv.appendChild(titleElement); const closeButtonElement = UI.createButton({ icon: 'close', className: 'artisan-modal-close-btn artisan-icon-button', onClick: typeof onCloseCallback === 'function' ? onCloseCallback : () => {}, title: "Close" }); headerDiv.appendChild(closeButtonElement); return headerDiv; },
        createFormGroup: (labelText, inputId, descriptionText = null) => { const group = document.createElement('div'); group.className = 'form-group'; const label = document.createElement('label'); label.htmlFor = inputId; label.textContent = labelText; if (descriptionText) label.title = descriptionText; group.appendChild(label); return group; },
        makeDraggable: (modalElement, dragHandleElement) => { let isDragging = false, offsetX, offsetY, initialModalX, initialModalY; if (!modalElement || !dragHandleElement) { return; } dragHandleElement.style.cursor = 'grab'; dragHandleElement.onmousedown = (e) => { if (e.target.closest('button, input, select, textarea, a, .artisan-modal-close-btn')) return; isDragging = true; dragHandleElement.style.cursor = 'grabbing'; const computedStyle = window.getComputedStyle(modalElement); const rect = modalElement.getBoundingClientRect(); const isTransformCentered = computedStyle.transform !== 'none' && computedStyle.transform.includes('translate(-50%, -50%)'); if (isTransformCentered && computedStyle.left === '50%' && computedStyle.top === '50%') { initialModalX = rect.left; initialModalY = rect.top; modalElement.style.left = `${initialModalX}px`; modalElement.style.top = `${initialModalY}px`; modalElement.style.transform = 'none'; } else { initialModalX = rect.left - parseFloat(computedStyle.marginLeft || '0'); initialModalY = rect.top - parseFloat(computedStyle.marginTop || '0');} offsetX = e.clientX - initialModalX; offsetY = e.clientY - initialModalY; modalElement.style.transition = 'none'; document.onmousemove = (ev) => { if (!isDragging) return; let newX = ev.clientX - offsetX; let newY = ev.clientY - offsetY; newX = Math.max(0, Math.min(newX, window.innerWidth - modalElement.offsetWidth)); newY = Math.max(0, Math.min(newY, window.innerHeight - modalElement.offsetHeight)); modalElement.style.left = `${newX}px`; modalElement.style.top = `${newY}px`; }; document.onmouseup = () => { if (!isDragging) return; isDragging = false; dragHandleElement.style.cursor = 'grab'; document.onmousemove = null; document.onmouseup = null; modalElement.style.transition = ''; }; e.preventDefault(); }; },
        createModalContainer: (title, onClose, sizeClass = '') => { const overlay = document.createElement('div'); const existingOverlayId = `overlay-${title.toLowerCase().replace(/\s+/g, '-')}`; const existingOverlay = document.getElementById(existingOverlayId); if (existingOverlay) existingOverlay.remove(); overlay.id = existingOverlayId; overlay.className = 'artisan-modal-overlay visible'; overlay.onclick = (e) => { if (e.target === overlay) { if (typeof onClose === 'function') onClose(); } }; const modal = document.createElement('div'); modal.className = `artisan-modal visible ${sizeClass}`; modal.id = `modal-${title.toLowerCase().replace(/\s+/g, '-')}`; modal.setAttribute('role', 'dialog'); modal.setAttribute('aria-modal', 'true'); modal.onclick = (e) => e.stopPropagation(); const header = UI.createModalHeader(title, () => { if (typeof onClose === 'function') onClose(); }); modal.setAttribute('aria-labelledby', header.querySelector('.artisan-modal-title').id); modal.appendChild(header); const contentTarget = document.createElement('div'); contentTarget.className = 'artisan-modal-content artisan-modal-content-target'; modal.appendChild(contentTarget); const footerTarget = document.createElement('div'); footerTarget.className = 'artisan-modal-footer artisan-modal-footer-target'; modal.appendChild(footerTarget); UI.makeDraggable(modal, header); overlay.appendChild(modal); return overlay; },
        createConfirmationModal: (message, onConfirmCallback, title = 'Confirm Action') => { if (UI.elements.confirmationModal) UI.elements.confirmationModal.remove(); const onCloseCleanup = () => { if (UI.elements.confirmationModal) UI.elements.confirmationModal.remove(); UI.elements.confirmationModal = null; }; const modalOverlay = UI.createModalContainer(title, onCloseCleanup, 'modal-size-small'); UI.elements.confirmationModal = modalOverlay; const content = modalOverlay.querySelector('.artisan-modal-content-target'); content.innerHTML = ''; const messageP = document.createElement('p'); messageP.textContent = message; messageP.style.padding = '1rem 0'; messageP.style.textAlign = 'center'; content.appendChild(messageP); const footer = modalOverlay.querySelector('.artisan-modal-footer-target'); footer.innerHTML = ''; const confirmBtn = UI.createButton({ text: "Confirm", className: "primary-action", onClick: () => { onConfirmCallback(); onCloseCleanup(); } }); const cancelBtn = UI.createButton({ text: "Cancel", className: "secondary-action", onClick: onCloseCleanup }); footer.append(cancelBtn, confirmBtn); if(UI.elements.rootContainer) UI.elements.rootContainer.appendChild(modalOverlay); modalOverlay.style.display = 'flex'; },
        createPromptModal: (message, defaultValue, onConfirmCallback, title = 'Input Required') => { if (UI.elements.promptModal) UI.elements.promptModal.remove(); const onCloseCleanup = () => { if (UI.elements.promptModal) UI.elements.promptModal.remove(); UI.elements.promptModal = null; }; const modalOverlay = UI.createModalContainer(title, onCloseCleanup, 'modal-size-medium'); UI.elements.promptModal = modalOverlay; const content = modalOverlay.querySelector('.artisan-modal-content-target'); content.innerHTML = ''; const messageP = document.createElement('p'); messageP.textContent = message; messageP.style.marginBottom = '0.75rem'; messageP.style.whiteSpace = 'pre-wrap'; const inputEl = document.createElement('input'); inputEl.type = 'text'; inputEl.value = defaultValue || ''; inputEl.className = 'artisan-prompt-modal-input'; inputEl.style.cssText = ` background-color: var(--artisan-bg-input); border: 1px solid var(--artisan-border-soft); color: var(--artisan-text-primary); border-radius: var(--artisan-radius-input); padding: 0.625rem; width: 100%; font-size: 0.95rem; box-sizing: border-box;`; inputEl.onfocus = () => { inputEl.style.borderColor = 'var(--artisan-accent-primary)'; inputEl.style.outline = '1px solid var(--artisan-accent-primary)'; inputEl.style.boxShadow = '0 0 0 2px var(--artisan-accent-primary-transparent)'; }; inputEl.onblur = () => { inputEl.style.borderColor = 'var(--artisan-border-soft)'; inputEl.style.outline = 'none'; inputEl.style.boxShadow = 'none'; }; content.append(messageP, inputEl); setTimeout(() => inputEl.focus(), 50); const footer = modalOverlay.querySelector('.artisan-modal-footer-target'); footer.innerHTML = ''; const okBtn = UI.createButton({ text: "OK", className: "primary-action", onClick: () => { onConfirmCallback(inputEl.value); onCloseCleanup(); } }); const cancelBtn = UI.createButton({ text: "Cancel", className: "secondary-action", onClick: onCloseCleanup }); footer.append(cancelBtn, okBtn); if(UI.elements.rootContainer) UI.elements.rootContainer.appendChild(modalOverlay); modalOverlay.style.display = 'flex'; },
        createAdvancedSettingsModal: () => { const modal = UI.createModalContainer('Advanced Cinematic Controls', () => { appState.ui.isAdvancedSettingsModalVisible = false; UI.render(); }, 'modal-size-xlarge'); const content = modal.querySelector('.artisan-modal-content-target'); UI.elements.advancedSettingsContainer = document.createElement('div'); UI.elements.advancedSettingsContainer.className = 'schema-grid'; if (!UI.elements.advancedSettingsInputsMap) UI.elements.advancedSettingsInputsMap = {}; const orderedSchemaKeys = ['aspectRatio', 'durationHint', 'composition_rule', 'shot_size', 'camera_angle', 'camera_movement', 'lens_type_optical_effects', 'lighting_style_atmosphere', 'visual_style_medium_era', 'vfx_post_production', 'color_palette_grading', 'editing_pace_transitions', 'subject_prominence', 'custom_elements']; orderedSchemaKeys.forEach(key => { let schemaDef, optionsArray, optionValuesArray, currentValue; if (key === 'aspectRatio') { schemaDef = { title: "Aspect Ratio", description: "Set aspect ratio." }; optionsArray = VEO_ASPECT_RATIOS_DISPLAY; optionValuesArray = VEO_ASPECT_RATIOS_VALUES; currentValue = appState.promptParams.advancedSettings[key] || VEO_ASPECT_RATIOS_VALUES[0]; } else if (key === 'durationHint') { schemaDef = { title: "Duration Hint", description: "Suggest length." }; optionsArray = VEO_DURATION_HINTS; optionValuesArray = VEO_DURATION_HINTS; currentValue = appState.promptParams.advancedSettings[key] || VEO_DURATION_HINTS[0]; } else { schemaDef = SCHEMA_INPUTS[key]; if (!schemaDef) return; optionsArray = schemaDef.enum; currentValue = appState.promptParams.advancedSettings[key] || SCHEMA_INPUTS[key]?.default || ''; } const itemDiv = UI.createFormGroup(schemaDef.title, `adv-schema-${key}`, schemaDef.description); itemDiv.classList.add('schema-item'); let inputEl; if (optionsArray) { inputEl = document.createElement('select'); optionsArray.forEach((optText, index) => { const opt = document.createElement('option'); opt.value = optionValuesArray ? optionValuesArray[index] : optText; opt.textContent = optText; inputEl.appendChild(opt); });} else { inputEl = document.createElement('input'); inputEl.type = schemaDef.type || 'text'; inputEl.placeholder = schemaDef.description || ''; } inputEl.id = `adv-schema-${key}`; inputEl.dataset.advKey = key; inputEl.value = currentValue; inputEl.onchange = Handlers.handleAdvancedSettingChange; if(key === 'custom_elements') inputEl.oninput = Utils.debounce(Handlers.handleAdvancedSettingChange, 250); UI.elements.advancedSettingsInputsMap[key] = inputEl; itemDiv.appendChild(inputEl); UI.elements.advancedSettingsContainer.appendChild(itemDiv); }); content.appendChild(UI.elements.advancedSettingsContainer); const footer = modal.querySelector('.artisan-modal-footer-target'); const clearAdvBtn = UI.createButton({ text: "Reset Advanced", icon: "delete_sweep", onClick: Handlers.handleClearAdvancedSettings, className: "tertiary-action"}); const doneBtn = UI.createButton({ text: "Done", icon: "check_circle", onClick: () => { appState.ui.isAdvancedSettingsModalVisible = false; UI.render(); }, className: "primary-action" }); footer.append(clearAdvBtn, doneBtn); return modal; },
        createHistoryModal: () => { const modal = UI.createModalContainer('Prompt Artisan History', () => { appState.ui.isHistoryPanelVisible = false; UI.render(); }, 'modal-size-xlarge'); const content = modal.querySelector('.artisan-modal-content-target'); if (appState.history.length === 0) content.innerHTML = '<p class="placeholder-text">No history recorded yet.</p>'; else { const ul = document.createElement('ul'); ul.className = 'history-list'; appState.history.forEach(item => { const li = document.createElement('li'); li.className = 'history-item artisan-card'; const detailsDiv = document.createElement('div'); detailsDiv.className = 'history-item-details'; let html = `<strong>${new Date(item.timestamp).toLocaleString()}</strong> <span class="history-tool-badge">${ARTISAN_PREAMBLE_CONFIG[item.modeUsed]?.displayName || item.modeUsed}</span><br>`; html += `Input: <em class="line-clamp-2">${(item.params.description || "").length > 0 ? (item.params.description || "") : "(No textual input)"}</em><br>`; if(item.params.uploadedImage) html += `Image: ${item.params.uploadedImage.name}<br>`; html += `Outputs: ${item.prompts.length}`; detailsDiv.innerHTML = html; const actionsDiv = document.createElement('div'); actionsDiv.className = 'history-item-actions'; const loadBtn = UI.createButton({ text: 'Load', icon: 'settings_backup_restore', onClick: () => Handlers.handleLoadFromHistory(item), title: "Load settings", className: "small-btn" }); actionsDiv.appendChild(loadBtn); li.appendChild(detailsDiv); li.appendChild(actionsDiv); ul.appendChild(li); }); content.appendChild(ul); } const footer = modal.querySelector('.artisan-modal-footer-target'); if (appState.history.length > 0) { const clearHistoryBtn = UI.createButton({ text: 'Clear History', icon: 'delete_sweep', onClick: Handlers.handleClearHistory, className: 'danger-action' }); footer.appendChild(clearHistoryBtn); } const closeBtn = UI.createButton({ text: 'Close', onClick: () => { appState.ui.isHistoryPanelVisible = false; UI.render(); }, className: 'secondary-action'}); footer.appendChild(closeBtn); return modal; },
        createFavoritesModal: () => { const modal = UI.createModalContainer('Favorite Prompts', () => { appState.ui.isFavoritesPanelVisible = false; UI.render(); }, 'modal-size-xlarge'); const content = modal.querySelector('.artisan-modal-content-target'); if (appState.favorites.length === 0) content.innerHTML = '<p class="placeholder-text">No favorites yet. Star a generated prompt to add it here.</p>'; else { const ul = document.createElement('ul'); ul.className = 'favorites-list'; appState.favorites.forEach(fav => { const item = document.createElement('li'); item.className = 'favorite-item artisan-card'; const detailsDiv = document.createElement('div'); detailsDiv.className = 'favorite-item-details line-clamp-3'; detailsDiv.textContent = fav.text; const actionsDiv = document.createElement('div'); actionsDiv.className = 'favorite-item-actions'; const useBtn = UI.createButton({ text: 'Use', icon: 'drive_file_rename_outline', onClick: () => { Handlers.handleUseAsBase(fav.text); appState.ui.isFavoritesPanelVisible = false; UI.render(); }, title: "Use as base input", className: "small-btn" }); const unfavBtn = UI.createButton({ icon: 'star', onClick: () => Handlers.handleToggleFavorite(fav.id, fav.text), title: "Unfavorite", className: "active small-btn icon-only" }); actionsDiv.append(useBtn, unfavBtn); item.append(detailsDiv, actionsDiv); ul.appendChild(item); }); content.appendChild(ul); } const footer = modal.querySelector('.artisan-modal-footer-target'); if (appState.favorites.length > 0) { const clearFavBtn = UI.createButton({ text: 'Clear All Favorites', icon: 'delete_sweep', onClick: Handlers.handleClearFavorites, className: 'danger-action' }); footer.appendChild(clearFavBtn); } const closeBtn = UI.createButton({ text: 'Close', onClick: () => { appState.ui.isFavoritesPanelVisible = false; UI.render(); }, className: 'secondary-action'}); footer.appendChild(closeBtn); return modal; },
        updateAdvancedSettingsInputs: () => { if (UI.elements.advancedSettingsInputsMap) { for (const key in UI.elements.advancedSettingsInputsMap) { const inputEl = UI.elements.advancedSettingsInputsMap[key]; if (inputEl) { let valueToSet; if (key === 'aspectRatio' || key === 'durationHint') valueToSet = appState.promptParams.advancedSettings[key] || (key === 'aspectRatio' ? VEO_ASPECT_RATIOS_VALUES[0] : VEO_DURATION_HINTS[0]); else valueToSet = appState.promptParams.advancedSettings[key] || SCHEMA_INPUTS[key]?.default || ''; inputEl.value = valueToSet; } } } },
        updateImagePreview: () => {
            if (!UI.elements.imagePreview) return;
            UI.elements.imagePreview.innerHTML = '';
            if (appState.promptParams.uploadedImage && appState.promptParams.uploadedImage.previewUrl) {
                const img = document.createElement('img'); img.src = appState.promptParams.uploadedImage.previewUrl; img.alt = "Image preview";
                const clearBtn = UI.createButton({ text: "Clear", icon: "close", onClick: Handlers.handleClearImage, className: "small-btn secondary-action" });
                UI.elements.imagePreview.append(img, clearBtn);
            } else {
                 UI.elements.imagePreview.innerHTML = '<span class="placeholder-text-inline">No image selected.</span>';
            }
        },
        injectCSS: () => {
            GM_addStyle(`
            :root {
                --artisan-font-primary: 'Google Sans Text', 'Roboto', 'Arial', sans-serif;
                --artisan-bg-base: #121212;
                --artisan-bg-panel: #1E1E1E;
                --artisan-bg-content: #282828;
                --artisan-bg-input: #333333;
                --artisan-bg-hover: #404040;
                --artisan-bg-active: #4A4A4A;
                --artisan-text-primary: #E0E0E0;
                --artisan-text-secondary: #B0B0B0;
                --artisan-text-tertiary: #888888;
                --artisan-border-soft: #383838;
                --artisan-border-strong: #4D4D4D;
                --artisan-accent-primary: #4A90E2; /* Vibrant Blue */
                --artisan-accent-primary-hover: #60A5FA;
                --artisan-accent-primary-transparent: rgba(74, 144, 226, 0.2);
                --artisan-accent-secondary: #81E6D9; /* Teal for secondary accents */
                --artisan-accent-favorite: #FACC15; /* Yellow for favorites */
                --artisan-error: #F87171;
                --artisan-success: #4ADE80;
                --artisan-warning: #FBBF24;
                --artisan-info: #60A5FA;
                --artisan-radius-main: 8px;
                --artisan-radius-input: 6px;
                --artisan-shadow-medium: 0 4px 12px rgba(0,0,0,0.3);
                --artisan-shadow-large: 0 10px 30px rgba(0,0,0,0.4);
                --artisan-scroll-thumb: #555;
                --artisan-scroll-track: #333;
            }
            #artisan-root-container, #artisan-root-container button, #artisan-root-container input, #artisan-root-container select, #artisan-root-container textarea { font-family: var(--artisan-font-primary); box-sizing: border-box; }
            .material-symbols-outlined { font-variation-settings: 'FILL' 0, 'wght' 300, 'GRAD' 0, 'opsz' 20; font-size: 20px; vertical-align: middle; line-height: 1; display: inline-block; }
            #artisan-root-container ::-webkit-scrollbar { width: 10px; height: 10px; }
            #artisan-root-container ::-webkit-scrollbar-track { background: var(--artisan-scroll-track); border-radius: var(--artisan-radius-input); }
            #artisan-root-container ::-webkit-scrollbar-thumb { background: var(--artisan-scroll-thumb); border-radius: var(--artisan-radius-input); border: 2px solid var(--artisan-scroll-track); }
            #artisan-root-container ::-webkit-scrollbar-thumb:hover { background: #666; }
            @keyframes fadeInOverlay { from { opacity: 0; } to { opacity: 1; } }
            @keyframes popInModal { from { opacity: 0; transform: translateY(20px) scale(0.98); } to { opacity: 1; transform: translateY(0) scale(1); } }
            @keyframes fadeInStatus { from { opacity:0; transform: translateY(10px); } to { opacity:1; transform: translateY(0); } }

            #artisan-fab-container { position: fixed !important; bottom: 25px !important; right: 25px !important; z-index: 20000 !important; display:flex !important; flex-direction:column-reverse !important; gap: 12px !important; align-items: flex-end !important; }
            .artisan-fab, .artisan-fab-secondary { background-color: var(--artisan-accent-primary) !important; color: white !important; border: none !important; border-radius: 50% !important; width: 60px !important; height: 60px !important; display: flex !important; align-items: center !important; justify-content: center !important; box-shadow: var(--artisan-shadow-medium) !important; cursor: pointer !important; transition: all 0.25s cubic-bezier(0.4, 0, 0.2, 1) !important; }
            .artisan-fab:hover, .artisan-fab-secondary:hover { background-color: var(--artisan-accent-primary-hover) !important; transform: scale(1.08) !important; }
            .artisan-fab .material-symbols-outlined, .artisan-fab-secondary .material-symbols-outlined { font-size: 28px !important; transition: transform 0.2s ease-in-out; }
            .artisan-fab.open .material-symbols-outlined { transform: rotate(45deg); }
            .artisan-fab-secondary { width: 52px !important; height: 52px !important; background-color: var(--artisan-bg-content) !important; color: var(--artisan-text-secondary) !important; }
            .artisan-fab-secondary:hover { background-color: var(--artisan-bg-hover) !important; color: var(--artisan-text-primary) !important; }
            .artisan-fab-options { display: flex; flex-direction: column-reverse; gap: 12px; transition: max-height 0.3s ease-in-out, opacity 0.3s ease-in-out, transform 0.3s ease-in-out; max-height: 0; opacity: 0; overflow: hidden; transform: translateY(10px); }
            .artisan-fab-options.open { max-height: 220px; opacity: 1; transform: translateY(0); }

            .artisan-modal-overlay { position: fixed; inset: 0; z-index: 9995; display: flex; align-items: center; justify-content: center; padding: 1rem; background-color: rgba(0,0,0,0.85); backdrop-filter: blur(5px); opacity:0; animation: fadeInOverlay 0.3s forwards; }
            .artisan-modal { background-color: var(--artisan-bg-panel); color: var(--artisan-text-primary); border-radius: var(--artisan-radius-main); box-shadow: var(--artisan-shadow-large); display: flex; flex-direction: column; max-height: 90vh; width: 100%; border: 1px solid var(--artisan-border-strong); opacity: 0; animation: popInModal 0.35s 0.05s cubic-bezier(0.4, 0, 0.2, 1) forwards; position: relative; }
            .artisan-modal.modal-size-xlarge { max-width: 1100px; } .artisan-modal.modal-size-large { max-width: 850px; } .artisan-modal.modal-size-medium { max-width: 650px; } .artisan-modal.modal-size-small { max-width: 480px; }
            #artisan-main-panel { position: fixed !important; bottom: 95px !important; right: 25px !important; width: 600px !important; max-width: calc(100vw - 50px) !important; max-height: calc(100vh - 120px) !important; z-index: 9992 !important; display: none; flex-direction: column !important; }
            #artisan-main-panel.visible { display: flex !important; }

            .artisan-modal-header { display: flex; justify-content: space-between; align-items: center; padding: 1rem 1.5rem; border-bottom: 1px solid var(--artisan-border-soft); cursor: grab; }
            .artisan-modal-title { font-size: 1.2rem; font-weight: 500; color: var(--artisan-text-primary); margin: 0; }
            .artisan-modal-content { flex-grow: 1; overflow-y: auto; padding: 0; scrollbar-width: thin; scrollbar-color: var(--artisan-scroll-thumb) var(--artisan-scroll-track); }
            #artisan-tab-content-container { padding: 1.5rem; } /* Add padding here for content within tabs */
            .artisan-modal-footer { display: flex; justify-content: flex-end; align-items: center; padding: 1rem 1.5rem; border-top: 1px solid var(--artisan-border-soft); gap: 0.75rem; background-color: var(--artisan-bg-content); border-radius: 0 0 var(--artisan-radius-main) var(--artisan-radius-main); }
            #artisan-main-panel-footer { border-radius: 0; background-color: transparent; } /* Main panel footer might be different */

            .artisan-button { display: inline-flex; align-items: center; justify-content: center; font-weight: 500; text-align: center; vertical-align: middle; cursor: pointer; user-select: none; border: 1px solid transparent; padding: 0.6rem 1.2rem; font-size: 0.9rem; border-radius: var(--artisan-radius-input); transition: all 0.2s ease-in-out; }
            .artisan-button:focus-visible { outline: 2px solid var(--artisan-accent-primary); outline-offset: 2px; }
            .artisan-button:disabled { opacity: 0.5; cursor: not-allowed; background-color: var(--artisan-bg-input) !important; color: var(--artisan-text-tertiary) !important; border-color: var(--artisan-border-soft) !important;}
            .artisan-button .material-symbols-outlined { font-size: 1.125em; }
            .artisan-button.primary-action { background-color: var(--artisan-accent-primary); color: white; }
            .artisan-button.primary-action:hover:not(:disabled) { background-color: var(--artisan-accent-primary-hover); box-shadow: 0 2px 8px rgba(74, 144, 226, 0.3); }
            .artisan-button.secondary-action { background-color: var(--artisan-bg-input); color: var(--artisan-text-primary); border: 1px solid var(--artisan-border-soft); }
            .artisan-button.secondary-action:hover:not(:disabled) { background-color: var(--artisan-bg-hover); border-color: var(--artisan-border-strong); }
            .artisan-button.tertiary-action { background-color: transparent; color: var(--artisan-text-secondary); border: 1px solid transparent; }
            .artisan-button.tertiary-action:hover:not(:disabled) { background-color: var(--artisan-bg-hover); color: var(--artisan-text-primary); }
            .artisan-button.danger-action { background-color: transparent; color: var(--artisan-error); border: 1px solid var(--artisan-error); }
            .artisan-button.danger-action:hover:not(:disabled) { background-color: rgba(248, 113, 113, 0.1); color: #FECACA; border-color: #FCA5A5; }
            .artisan-icon-button { background-color: transparent; color: var(--artisan-text-secondary); border-radius: 50%; padding: 0.5rem; border: none; width: 36px; height:36px; }
            .artisan-icon-button:hover:not(:disabled) { background-color: var(--artisan-bg-hover); color: var(--artisan-text-primary); }
            .artisan-button.small-btn { padding: 0.375rem 0.75rem; font-size: 0.8rem; }
            .artisan-button.small-btn .material-symbols-outlined { font-size: 1rem; }

            .form-group { margin-bottom: 1.25rem; text-align: left; }
            .form-label, .form-group label { display: block; margin-bottom: 0.5rem; font-size: 0.875rem; font-weight: 500; color: var(--artisan-text-secondary); }
            .form-group input[type="text"], .form-group input[type="file"], .form-group textarea, .form-group select { background-color: var(--artisan-bg-input); border: 1px solid var(--artisan-border-soft); color: var(--artisan-text-primary); border-radius: var(--artisan-radius-input); padding: 0.75rem; width: 100%; font-size: 0.95rem; transition: border-color 0.2s, box-shadow 0.2s; }
            .form-group input[type="text"]:focus, .form-group textarea:focus, .form-group select:focus { border-color: var(--artisan-accent-primary); outline: none; box-shadow: 0 0 0 3px var(--artisan-accent-primary-transparent); }
            .form-group textarea { min-height: 90px; resize: vertical; line-height: 1.6; }
            .form-group select { appearance: none; -webkit-appearance: none; -moz-appearance: none; background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' fill='none' viewBox='0 0 20 20'%3E%3Cpath stroke='%239CA3AF' stroke-linecap='round' stroke-linejoin='round' stroke-width='1.5' d='M6 8l4 4 4-4'/%3E%3C/svg%3E"); background-repeat: no-repeat; background-position: right 0.85rem center; background-size: 1.1em; padding-right: 2.8rem; }
            .form-group select option { background-color: var(--artisan-bg-panel); color: var(--artisan-text-primary); }

            .artisan-tab-nav { display: flex; flex-wrap: nowrap; overflow-x: auto; background-color: var(--artisan-bg-content); padding: 0.375rem 1rem 0 1rem; /* Adjusted horizontal padding */ border-bottom: 1px solid var(--artisan-border-strong); gap: 0.5rem; /* Adjusted gap between tabs */ scrollbar-width: thin; scrollbar-color: var(--artisan-scroll-thumb) var(--artisan-scroll-track); }
            .artisan-tab-nav::-webkit-scrollbar { height: 6px; }
            .artisan-tab-nav::-webkit-scrollbar-thumb { background: var(--artisan-scroll-thumb); border-radius:3px; }
            .artisan-tab-nav::-webkit-scrollbar-button { display: none; } /* Hide scrollbar buttons for tab nav */
            .artisan-tab-button { padding: 0.75rem 1rem; cursor: pointer; color: var(--artisan-text-secondary); border-bottom: 3px solid transparent; transition: color 0.2s, border-color 0.2s, background-color 0.2s; font-size: 0.9rem; font-weight: 500; display: inline-flex; align-items: center; gap: 0.6em; /* Adjusted icon-text gap */ white-space: nowrap; border-radius: var(--artisan-radius-input) var(--artisan-radius-input) 0 0; margin-top:0.25rem; position: relative; top: 1px; }
            .artisan-tab-button:hover { color: var(--artisan-text-primary); background-color: var(--artisan-bg-hover); }
            .artisan-tab-button.active { color: var(--artisan-accent-primary); border-bottom-color: var(--artisan-accent-primary); background-color: var(--artisan-bg-panel); } /* Ensure active tab bg matches content area */
            .artisan-tab-button .material-symbols-outlined { font-size: 1.1em; }
            .tool-description { font-size: 0.9rem; color: var(--artisan-text-secondary); margin-bottom: 1.5rem; padding: 1rem; background-color: var(--artisan-bg-input); border-radius: var(--artisan-radius-input); border: 1px solid var(--artisan-border-soft); line-height: 1.6; }
            .tab-actions { display: flex; gap: 1rem; margin-top: 1.5rem; border-top: 1px solid var(--artisan-border-soft); padding-top: 1.5rem; }
            .image-preview-area { display: flex; align-items: center; gap: 0.75rem; margin-top: 0.5rem; padding: 0.5rem; background-color: var(--artisan-bg-input); border-radius: var(--artisan-radius-input); min-height: 50px;}
            .image-preview-area img { max-width: 120px; max-height: 80px; border-radius: calc(var(--artisan-radius-input) - 2px); object-fit: contain; border: 1px solid var(--artisan-border-soft); }
            .placeholder-text-inline { font-size: 0.85rem; color: var(--artisan-text-tertiary); }
            .live-preview-area { background-color: var(--artisan-bg-input); border: 1px dashed var(--artisan-border-soft); padding: 1rem; margin-top:0.5rem; border-radius: var(--artisan-radius-input); font-size: 0.85rem; color: var(--artisan-text-secondary); white-space: pre-wrap; min-height: 80px; max-height: 180px; overflow-y: auto; line-height: 1.6; }
            .results-section { margin-top: 1.5rem; }
            .results-section h3 { font-size: 1.1rem; color: var(--artisan-text-primary); margin-bottom: 1rem; padding-bottom: 0.5rem; border-bottom: 1px solid var(--artisan-border-soft); }
            .prompt-list { list-style:none; padding:0; margin:0; display: flex; flex-direction: column; gap: 1rem; }
            .artisan-card { background-color: var(--artisan-bg-content); padding: 1rem 1.25rem; border-radius: var(--artisan-radius-input); border: 1px solid var(--artisan-border-soft); box-shadow: 0 2px 4px rgba(0,0,0,0.1); transition: box-shadow 0.2s; }
            .artisan-card:hover { box-shadow: 0 3px 8px rgba(0,0,0,0.15); }
            .prompt-list li { display:flex; justify-content:space-between; align-items:flex-start; gap:1rem; }
            .prompt-text-display { flex-grow:1; white-space:pre-wrap; word-break:break-word; font-size:0.95rem; line-height:1.6; color: var(--artisan-text-primary); }
            .prompt-item-actions { display:flex; flex-direction:row; gap:0.5rem; flex-shrink:0; align-items:center; }
            .prompt-item-actions .artisan-button { padding: 0.5rem; } /* Make icon buttons in results a bit larger */
            .prompt-item-actions .artisan-button .material-symbols-outlined { font-size: 1.25rem; }
            .favorite-btn.active .material-symbols-outlined { color: var(--artisan-accent-favorite); font-variation-settings: 'FILL' 1; }
            .placeholder-text { color: var(--artisan-text-tertiary); text-align:center; padding: 2rem 1rem; font-size: 0.95rem; }

            #artisan-global-status { position: fixed; bottom: 20px; left: 50%; transform: translateX(-50%); width: auto; max-width:90%; z-index: 20001 !important; pointer-events: none; display:flex; flex-direction:column; align-items:center; gap: 0.75rem;}
            .loading-indicator.global-loading, .message-global { padding: 0.85rem 1.5rem; border-radius: var(--artisan-radius-input); display: inline-flex; align-items: center; justify-content: center; box-shadow: var(--artisan-shadow-medium); pointer-events: auto; max-width: calc(100% - 40px); word-break: break-word; font-size: 0.95rem; opacity:0; animation: fadeInStatus 0.3s forwards; border: 1px solid transparent; }
            .loading-indicator.global-loading { background: var(--artisan-bg-content); color: var(--artisan-text-primary); border-color: var(--artisan-border-soft); }
            .message-global.error-message { background: var(--artisan-error); color: white; }
            .message-global.success-message { background: var(--artisan-success); color: #065F46; } /* Darker green text for contrast */
            .message-global.info-message { background: var(--artisan-info); color: white; }
            .message-global.warning-message { background: var(--artisan-warning); color: #78350F; } /* Darker amber text */
            #artisan-global-status .material-symbols-outlined { margin-right: 0.6rem; font-size: 1.25em; }
            .message-global .artisan-button.small-btn { margin-left: 0.75rem; padding: 0.25rem; background: rgba(255,255,255,0.1); color: white; }
            .message-global.success-message .artisan-button.small-btn, .message-global.warning-message .artisan-button.small-btn { color: inherit; background: rgba(0,0,0,0.1); }


            .history-list, .favorites-list { list-style-type: none; padding: 0; display: flex; flex-direction: column; gap: 1rem; }
            .history-item, .favorite-item { display: flex; justify-content: space-between; align-items: center; gap: 1rem; } /* .artisan-card handles styling */
            .history-item-details, .favorite-item-details { flex-grow: 1; font-size: 0.9rem; color: var(--artisan-text-secondary); line-height:1.5; }
            .history-item-details strong, .favorite-item-details strong { color: var(--artisan-text-primary); font-weight: 500; }
            .history-item-details em { font-style: italic; color: var(--artisan-text-tertiary); }
            .history-tool-badge { background-color: var(--artisan-accent-secondary); color: #1A3633; padding: 0.15rem 0.4rem; border-radius: 4px; font-size: 0.75rem; margin-left: 0.5rem; font-weight: 500; display:inline-block; vertical-align:middle;}
            .history-item-actions, .favorite-item-actions { display:flex; gap:0.5rem; flex-shrink:0; }
            .line-clamp-2 { display: -webkit-box; -webkit-line-clamp: 2; -webkit-box-orient: vertical; overflow: hidden; text-overflow: ellipsis; }
            .line-clamp-3 { display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden; text-overflow: ellipsis; }
            .schema-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 1.25rem; padding: 0.5rem; }
            .schema-item { background-color: var(--artisan-bg-content); padding: 1rem; border-radius: var(--artisan-radius-input); border: 1px solid var(--artisan-border-soft); }
            .schema-item label { font-weight: 500; color: var(--artisan-text-primary); }
            .schema-item .form-group { margin-bottom: 0; } /* Remove bottom margin from form-group inside schema-item */
            `);
        },
        showGlobalMessage: (message, type = 'info', duration = 3500) => { if (!UI.elements.globalStatusArea) return; const messageDiv = document.createElement('div'); messageDiv.className = `message-global ${type}-message`; let iconName = 'info'; if (type === 'error') iconName = 'error'; else if (type === 'success') iconName = 'check_circle_filled'; else if (type === 'warning') iconName = 'warning'; messageDiv.appendChild(UI.createIcon(iconName)); messageDiv.appendChild(document.createTextNode(message)); UI.elements.globalStatusArea.appendChild(messageDiv); setTimeout(() => { messageDiv.style.opacity = '0'; messageDiv.style.transform = 'translateY(10px)'; setTimeout(() => messageDiv.remove(), 300); }, duration); },
        renderAppStatus: () => { if (!UI.elements.globalStatusArea) return; const existingLoading = UI.elements.globalStatusArea.querySelector('.loading-indicator.global-loading'); if (existingLoading) existingLoading.remove(); const existingError = UI.elements.globalStatusArea.querySelector('.message-global.error-message.persistent'); if(existingError) existingError.remove(); if (appState.isLoading && appState.currentActionMessage) { const loadingDiv = document.createElement('div'); loadingDiv.className = 'loading-indicator global-loading'; loadingDiv.appendChild(UI.createIcon('hourglass_top')); loadingDiv.appendChild(document.createTextNode(appState.currentActionMessage)); UI.elements.globalStatusArea.appendChild(loadingDiv); } else if (appState.error) { const errorDiv = document.createElement('div'); errorDiv.className = 'message-global error-message persistent'; errorDiv.appendChild(UI.createIcon('error')); errorDiv.appendChild(document.createTextNode(`Error: ${appState.error}`)); const closeBtn = UI.createButton({icon: 'close', className: 'small-btn icon-only', onClick: () => { appState.error = null; UI.renderAppStatus(); }, title: "Dismiss error"}); errorDiv.appendChild(closeBtn); UI.elements.globalStatusArea.appendChild(errorDiv); } },
        renderActiveTabContent: () => {
            if (!UI.elements.tabContentContainer) return;
            UI.elements.tabContentContainer.innerHTML = ''; // Clear previous content

            const activeToolId = appState.ui.activeToolId;
            const modeConfig = ARTISAN_PREAMBLE_CONFIG[activeToolId];
            if (!modeConfig) { UI.elements.tabContentContainer.textContent = 'Error: Tool configuration not found.'; return; }

            const descriptionDiv = document.createElement('div');
            descriptionDiv.className = 'tool-description';
            descriptionDiv.textContent = modeConfig.description || `Use this tool to: ${modeConfig.displayName}. ${modeConfig.promptPlaceholder || ''}`;
            UI.elements.tabContentContainer.appendChild(descriptionDiv);

            const inputSection = document.createElement('div');
            inputSection.className = 'input-controls-section';

            const promptGroup = UI.createFormGroup(modeConfig.displayName === "Parameter Explainer" ? 'Parameter/Concept/Question' : 'Primary Input / Concept', `artisan-prompt-input-${activeToolId}`);
            UI.elements.promptInput = document.createElement('textarea');
            UI.elements.promptInput.id = `artisan-prompt-input-${activeToolId}`;
            UI.elements.promptInput.value = appState.promptParams.description;
            UI.elements.promptInput.rows = modeConfig.type === 'critique_enhance' ? 6 : 4;
            UI.elements.promptInput.placeholder = modeConfig.promptPlaceholder || 'Enter your text here...';
            UI.elements.promptInput.oninput = Utils.debounce(Handlers.handleDescriptionChange, 250);
            promptGroup.appendChild(UI.elements.promptInput);
            inputSection.appendChild(promptGroup);

            if (modeConfig.type === 'generation' || modeConfig.type === 'extension' || modeConfig.type === 'critique_enhance' || modeConfig.requiresInputType === 'core_concept_for_inference' ) {
                const negPromptGroup = UI.createFormGroup('Negative Keywords (Optional)', `artisan-negative-prompt-${activeToolId}`);
                UI.elements.negativePromptInput = document.createElement('textarea');
                UI.elements.negativePromptInput.id = `artisan-negative-prompt-${activeToolId}`;
                UI.elements.negativePromptInput.placeholder = "e.g., text, watermark, blurry, low quality";
                UI.elements.negativePromptInput.value = appState.promptParams.negativePrompt;
                UI.elements.negativePromptInput.rows = 2;
                UI.elements.negativePromptInput.oninput = Utils.debounce(Handlers.handleNegativePromptChange, 250);
                negPromptGroup.appendChild(UI.elements.negativePromptInput);
                inputSection.appendChild(negPromptGroup);
            }

            if (modeConfig.type === 'generation' || modeConfig.type === 'extension' || modeConfig.requiresInputType === 'core_concept_for_inference') {
                const imgUploadSection = document.createElement('div');
                imgUploadSection.className = 'image-upload-section form-group';
                const imgLabel = document.createElement('label'); imgLabel.textContent = 'Image Reference (Optional)'; imgLabel.className = 'form-label';
                UI.elements.imageUploadInput = document.createElement('input');
                UI.elements.imageUploadInput.type = 'file'; UI.elements.imageUploadInput.id = `artisan-image-upload-${activeToolId}`;
                UI.elements.imageUploadInput.accept = ALLOWED_IMAGE_TYPES.join(','); UI.elements.imageUploadInput.style.display = 'none';
                UI.elements.imageUploadInput.onchange = Handlers.handleImageUpload;
                const uploadButton = UI.createButton({ text: "Upload Image", icon: "attach_file", onClick: () => UI.elements.imageUploadInput.click(), title: `Upload an image (Max ${MAX_IMAGE_SIZE_BYTES / (1024*1024)}MB)`, className: "secondary-action" });
                UI.elements.imagePreview = document.createElement('div'); UI.elements.imagePreview.className = 'image-preview-area';
                imgUploadSection.append(imgLabel, UI.elements.imageUploadInput, uploadButton, UI.elements.imagePreview);
                inputSection.appendChild(imgUploadSection);
                UI.updateImagePreview();
            }

            if (modeConfig.showSchemaControls) {
                const controlsGrid = document.createElement('div');
                controlsGrid.style.display = 'grid';
                controlsGrid.style.gridTemplateColumns = '1fr 1fr';
                controlsGrid.style.gap = '1rem';

                const audioGroup = UI.createFormGroup('Audio Detail Level', `artisan-audio-level-${activeToolId}`);
                UI.elements.audioLevelSelect = document.createElement('select'); UI.elements.audioLevelSelect.id = `artisan-audio-level-${activeToolId}`;
                VEO_AUDIO_PROMPTING_LEVELS_VALUES.forEach((val, idx) => { const opt = document.createElement('option'); opt.value = val; opt.textContent = VEO_AUDIO_PROMPTING_LEVELS_DISPLAY[idx]; UI.elements.audioLevelSelect.appendChild(opt); });
                UI.elements.audioLevelSelect.value = appState.promptParams.audioPromptingLevel; UI.elements.audioLevelSelect.onchange = Handlers.handleAudioLevelChange;
                audioGroup.appendChild(UI.elements.audioLevelSelect);
                controlsGrid.appendChild(audioGroup);

                const styleGroup = UI.createFormGroup('Visual Style', `artisan-style-${activeToolId}`);
                UI.elements.styleSelect = document.createElement('select'); UI.elements.styleSelect.id = `artisan-style-${activeToolId}`;
                VEO_STYLES.forEach(style => { const opt = document.createElement('option'); opt.value = style; opt.textContent = style === "" ? "Any / Auto-Infer" : style; UI.elements.styleSelect.appendChild(opt); });
                UI.elements.styleSelect.value = appState.promptParams.style; UI.elements.styleSelect.onchange = Handlers.handleStyleChange;
                styleGroup.appendChild(UI.elements.styleSelect);
                controlsGrid.appendChild(styleGroup);
                inputSection.appendChild(controlsGrid);

                if (modeConfig.showAdvancedSettingsLink) {
                    UI.elements.advancedSettingsLinkSection = document.createElement('div');
                    UI.elements.advancedSettingsLinkSection.className = 'advanced-settings-link-section form-group'; // Re-use form-group for spacing
                    UI.elements.advancedSettingsLinkSection.style.marginTop = '1rem'; // Add some top margin
                    const advBtn = UI.createButton({ text: "Advanced Cinematic Controls", icon: "tune", className: "secondary-action advanced-settings-btn", onClick: () => { appState.ui.isAdvancedSettingsModalVisible = true; UI.render(); }, title: "Configure detailed camera, lighting, etc."});
                    advBtn.style.width = '100%';
                    UI.elements.advancedSettingsLinkSection.appendChild(advBtn);
                    inputSection.appendChild(UI.elements.advancedSettingsLinkSection);
                }
            }

            if (modeConfig.type === 'generation' || modeConfig.type === 'extension') {
                const ccGroup = UI.createFormGroup('Number of Outputs', `artisan-candidate-count-${activeToolId}`);
                UI.elements.candidateCountSelect = document.createElement('select'); UI.elements.candidateCountSelect.id = `artisan-candidate-count-${activeToolId}`;
                [1,2,3,4,5,6,7,8].forEach(num => { const opt=document.createElement('option'); opt.value=num; opt.textContent=num; UI.elements.candidateCountSelect.appendChild(opt); });
                UI.elements.candidateCountSelect.value = appState.promptParams.candidateCount; UI.elements.candidateCountSelect.onchange = Handlers.handleCandidateCountChange;
                ccGroup.appendChild(UI.elements.candidateCountSelect); inputSection.appendChild(ccGroup);
            }
            UI.elements.tabContentContainer.appendChild(inputSection);

            if (modeConfig.type === 'generation' || modeConfig.type === 'extension') {
                const livePreviewSection = document.createElement('div');
                livePreviewSection.className = 'form-group'; // Re-use for consistent spacing
                const livePreviewLabel = document.createElement('label'); livePreviewLabel.textContent = "Live AI Instruction Preview"; livePreviewLabel.className = "form-label";
                UI.elements.livePreviewArea = document.createElement('div'); UI.elements.livePreviewArea.id = 'artisan-live-preview'; UI.elements.livePreviewArea.className = 'live-preview-area';
                livePreviewSection.append(livePreviewLabel, UI.elements.livePreviewArea);
                UI.elements.tabContentContainer.appendChild(livePreviewSection);
                Handlers.handleLivePreviewUpdate();
            }

            const actionsContainer = document.createElement('div');
            actionsContainer.className = 'tab-actions';

            const mainActionBtn = UI.createButton({ text: modeConfig.actionButtonText || "Run Tool", icon: modeConfig.icon || "play_circle", className: "primary-action", onClick: Handlers.handleSubmit, title: `Run ${modeConfig.displayName}` });
            actionsContainer.appendChild(mainActionBtn);
            const clearToolInputBtn = UI.createButton({ text: "Clear Inputs", icon: "clear_all", className: "secondary-action", onClick: Handlers.handleClearCurrentToolInputs, title: "Clear inputs for the current tool" });
            actionsContainer.appendChild(clearToolInputBtn);
            UI.elements.tabContentContainer.appendChild(actionsContainer);

            UI.elements.resultsContainer = document.createElement('div');
            UI.elements.tabContentContainer.appendChild(UI.elements.resultsContainer);
            UI.createResultsSection();
        },
        createResultsSection: () => {
            if (!UI.elements.resultsContainer) { return; }
            UI.elements.resultsContainer.innerHTML = '';
            UI.elements.resultsContainer.className = 'results-section';
            const activeToolId = appState.ui.activeToolId;
            const modeConfig = ARTISAN_PREAMBLE_CONFIG[activeToolId];
            const title = document.createElement('h3');
            title.textContent = (modeConfig?.type?.startsWith('utility') || modeConfig?.type === 'critique_enhance' || modeConfig?.type === 'utility_infer' || modeConfig?.type === 'utility_surprise') ? 'Tool Output / Suggestions' : 'Generated Prompts';
            UI.elements.resultsContainer.appendChild(title);
            if (appState.generatedPrompts.length > 0) {
                const list = document.createElement('ul'); list.className = 'prompt-list';
                appState.generatedPrompts.forEach(prompt => {
                    const item = document.createElement('li'); item.className = 'artisan-card'; // Use card style for each prompt
                    const textDiv = document.createElement('div'); textDiv.className = 'prompt-text-display';
                    if (modeConfig?.type === 'critique_enhance' || modeConfig?.type === 'utility_tool' || modeConfig?.type === 'utility_infer' || modeConfig?.type === 'utility_surprise' || activeToolId === 'Veo3_Narrative_Arc' || activeToolId === 'Veo3_Character_Concept' || activeToolId === 'Veo3_Environment_Design') {
                        let htmlContent = prompt.text.replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>') // Bold
                                                   .replace(/---(SCENE|CHARACTER|ENVIRONMENT|PROMPT) BREAK---/g, '<hr style="border-color: var(--artisan-border-soft); margin: 0.75rem 0;">') // Separators
                                                   .replace(/\n/g, '<br>');
                        textDiv.innerHTML = htmlContent;
                    } else { textDiv.textContent = prompt.text; }
                    const actionsDiv = document.createElement('div'); actionsDiv.className = 'prompt-item-actions';
                    const copyBtn = UI.createButton({ icon: "content_copy", title: "Copy Output", onClick: () => Handlers.handleCopyText(prompt.text, copyBtn), className: "icon-only tertiary-action" });
                    actionsDiv.appendChild(copyBtn);
                    if (modeConfig && (modeConfig.type === 'generation' || modeConfig.type === 'extension' || (modeConfig.type === 'critique_enhance' && prompt.text.includes('Enhanced Prompt:')))) {
                        let textToUseAsBase = prompt.text;
                        if (modeConfig.type === 'critique_enhance') { const match = prompt.text.match(/Enhanced Prompt:\s*([\s\S]*)/i); textToUseAsBase = (match && match[1]) ? match[1].trim() : ""; }
                         // For multi-part outputs, "Use as Base" might take the whole block or first part. Let's assume whole block for now.
                        if (textToUseAsBase) {
                            const useBtn = UI.createButton({ icon: "drive_file_rename_outline", title: "Use as Base Input", onClick: () => Handlers.handleUseAsBase(textToUseAsBase), className: "icon-only tertiary-action" });
                            actionsDiv.appendChild(useBtn);
                            const isFav = appState.favorites.some(fav => fav.id === prompt.id || fav.text === textToUseAsBase);
                            const favBtn = UI.createButton({ icon: isFav ? "star" : "star_outline", title: isFav ? "Unfavorite" : "Favorite", className: (isFav ? "favorite-btn active" : "favorite-btn") + " icon-only tertiary-action", onClick: () => Handlers.handleToggleFavorite(prompt.id, textToUseAsBase) });
                            actionsDiv.appendChild(favBtn);
                        }
                    }
                    item.appendChild(textDiv); item.appendChild(actionsDiv); list.appendChild(item);
                });
                UI.elements.resultsContainer.appendChild(list);
            } else if (!appState.isLoading && !appState.error) { const p = document.createElement('p'); p.textContent = "No outputs yet. Configure and run the tool."; p.className = "placeholder-text"; UI.elements.resultsContainer.appendChild(p); }
        },
        init: () => {
            UI.injectCSS();
            UI.elements.rootContainer = document.createElement('div'); UI.elements.rootContainer.id = 'artisan-root-container';
            document.body.appendChild(UI.elements.rootContainer);

            UI.elements.fabContainer = document.createElement('div'); UI.elements.fabContainer.id = 'artisan-fab-container';
            const fabOptionsContainer = document.createElement('div'); fabOptionsContainer.id = 'artisan-fab-options'; fabOptionsContainer.className = 'artisan-fab-options';
            UI.elements.historyFab = UI.createButton({ icon: "history", className: "artisan-fab-secondary", onClick: Handlers.toggleHistoryPanel, title: "Toggle History" });
            UI.elements.favoritesFab = UI.createButton({ icon: "star_outline", className: "artisan-fab-secondary", onClick: Handlers.toggleFavoritesPanel, title: "Toggle Favorites" });
            fabOptionsContainer.append(UI.elements.historyFab, UI.elements.favoritesFab);
            UI.elements.mainFab = UI.createButton({ icon: "auto_fix_high", className: "artisan-fab", onClick: Handlers.toggleMainFabMenu, title: "Toggle AI Artisan Tools Menu" }); // Changed icon and handler
            UI.elements.fabContainer.append(fabOptionsContainer, UI.elements.mainFab);
            UI.elements.rootContainer.appendChild(UI.elements.fabContainer);

            UI.elements.mainPanel = document.createElement('div'); UI.elements.mainPanel.id = 'artisan-main-panel'; UI.elements.mainPanel.className = 'artisan-modal'; // Use modal class for base styling
            UI.elements.mainPanelHeaderElement = UI.createModalHeader(`AI Artisan Tools v${SCRIPT_VERSION}`, Handlers.toggleMainPanelVisibility); // Specific handler for panel
            UI.makeDraggable(UI.elements.mainPanel, UI.elements.mainPanelHeaderElement);

            UI.elements.tabNavContainer = document.createElement('div'); UI.elements.tabNavContainer.className = 'artisan-tab-nav';
            Object.keys(ARTISAN_PREAMBLE_CONFIG).forEach(toolId => {
                const toolConfig = ARTISAN_PREAMBLE_CONFIG[toolId];
                const tabButton = UI.createButton({ text: toolConfig.displayName, icon: toolConfig.icon || 'build_circle', className: 'artisan-tab-button', onClick: () => Handlers.handleTabClick(toolId), title: toolConfig.displayName });
                tabButton.dataset.toolId = toolId;
                UI.elements.tabNavContainer.appendChild(tabButton);
            });

            UI.elements.tabContentContainer = document.createElement('div'); UI.elements.tabContentContainer.id = 'artisan-tab-content-container'; UI.elements.tabContentContainer.className = 'artisan-modal-content'; // Use modal-content for consistent padding/scrolling
            UI.elements.mainPanelFooter = document.createElement('div'); UI.elements.mainPanelFooter.id = 'artisan-main-panel-footer'; UI.elements.mainPanelFooter.className = 'artisan-modal-footer'; // Use modal-footer for styling
            const closeButton = UI.createButton({ text: "Close Panel", icon:"close", className: "secondary-action", onClick: Handlers.toggleMainPanelVisibility });
            UI.elements.mainPanelFooter.appendChild(closeButton);
            UI.elements.mainPanel.append(UI.elements.mainPanelHeaderElement, UI.elements.tabNavContainer, UI.elements.tabContentContainer, UI.elements.mainPanelFooter);
            UI.elements.rootContainer.appendChild(UI.elements.mainPanel);

            UI.elements.globalStatusArea = document.createElement('div'); UI.elements.globalStatusArea.id = 'artisan-global-status';
            UI.elements.rootContainer.appendChild(UI.elements.globalStatusArea);
        },
        render: () => {
            if (!UI.elements.rootContainer) { console.error("Artisan: Root container not found."); return; }
            const fabOptionsContainer = document.getElementById('artisan-fab-options');
            if (fabOptionsContainer) fabOptionsContainer.classList.toggle('open', appState.ui.isFabMenuOpen);
            if (UI.elements.mainFab) { UI.elements.mainFab.innerHTML = ''; UI.elements.mainFab.appendChild(UI.createIcon(appState.ui.isFabMenuOpen ? 'close' : 'auto_fix_high')); UI.elements.mainFab.classList.toggle('open', appState.ui.isFabMenuOpen); }

            if (UI.elements.mainPanel) {
                UI.elements.mainPanel.classList.toggle('visible', appState.ui.isMainPanelVisible);
                if (appState.ui.isMainPanelVisible) {
                    if (UI.elements.tabNavContainer) {
                        Array.from(UI.elements.tabNavContainer.children).forEach(tabBtn => {
                           if (tabBtn instanceof HTMLElement) tabBtn.classList.toggle('active', tabBtn.dataset.toolId === appState.ui.activeToolId);
                        });
                    }
                    UI.renderActiveTabContent();
                }
            }

            if (appState.ui.isHistoryPanelVisible && !UI.elements.historyModal) { UI.elements.historyModal = UI.createHistoryModal(); if(UI.elements.rootContainer) UI.elements.rootContainer.appendChild(UI.elements.historyModal); }
            else if (!appState.ui.isHistoryPanelVisible && UI.elements.historyModal) { UI.elements.historyModal.remove(); UI.elements.historyModal = null; }
            if (appState.ui.isFavoritesPanelVisible && !UI.elements.favoritesModal) { UI.elements.favoritesModal = UI.createFavoritesModal(); if(UI.elements.rootContainer) UI.elements.rootContainer.appendChild(UI.elements.favoritesModal); }
            else if (!appState.ui.isFavoritesPanelVisible && UI.elements.favoritesModal) { UI.elements.favoritesModal.remove(); UI.elements.favoritesModal = null; }
            if (UI.elements.favoritesFab) { const favIcon = UI.elements.favoritesFab.querySelector('.material-symbols-outlined'); if(favIcon) { favIcon.textContent = appState.favorites.length > 0 ? 'star' : 'star_outline'; favIcon.style.fontVariationSettings = appState.favorites.length > 0 ? "'FILL' 1" : "'FILL' 0"; } }
            if (appState.ui.isAdvancedSettingsModalVisible && !UI.elements.advancedSettingsModal) { UI.elements.advancedSettingsModal = UI.createAdvancedSettingsModal(); if(UI.elements.rootContainer) UI.elements.rootContainer.appendChild(UI.elements.advancedSettingsModal); UI.updateAdvancedSettingsInputs(); }
            else if (!appState.ui.isAdvancedSettingsModalVisible && UI.elements.advancedSettingsModal) { UI.elements.advancedSettingsModal.remove(); UI.elements.advancedSettingsModal = null; }
            if (appState.ui.isAdvancedSettingsModalVisible && UI.elements.advancedSettingsModal) { UI.updateAdvancedSettingsInputs(); }
            UI.renderAppStatus();
        },
    });

    // --- Handlers Object ---
    Object.assign(Handlers, {
        initAppState: () => {
            appState.ui.activeToolId = GM_getValue(STORAGE_KEYS.ACTIVE_TOOL_ID) || Object.keys(ARTISAN_PREAMBLE_CONFIG)[0];
            appState.promptParams.artisanMode = appState.ui.activeToolId;
            appState.promptParams.audioPromptingLevel = GM_getValue(STORAGE_KEYS.SELECTED_AUDIO_LEVEL) || DEFAULT_AUDIO_LEVEL;
            appState.promptParams.style = GM_getValue(STORAGE_KEYS.SELECTED_STYLE) || DEFAULT_STYLE_KEY;
            const freshAdvancedSettings = { aspectRatio: VEO_ASPECT_RATIOS_VALUES[0], durationHint: VEO_DURATION_HINTS[0] };
            for (const key in SCHEMA_INPUTS) { freshAdvancedSettings[key] = SCHEMA_INPUTS[key].default || ''; }
            appState.promptParams.advancedSettings = { ...freshAdvancedSettings };
            appState.history = Storage.loadHistory(); appState.favorites = Storage.loadFavorites();
        },
        toggleMainFabMenu: () => { appState.ui.isFabMenuOpen = !appState.ui.isFabMenuOpen; if (!appState.ui.isFabMenuOpen && appState.ui.isMainPanelVisible) { /* If closing menu but panel is open, do nothing special */ } else if (appState.ui.isFabMenuOpen) { appState.ui.isMainPanelVisible = false; /* Open menu implies panel closes if it was open */ } else { /* If closing menu and panel was not open, or if opening menu, then toggle panel */ appState.ui.isMainPanelVisible = !appState.ui.isMainPanelVisible; } UI.render(); },
        toggleMainPanelVisibility: () => { appState.ui.isMainPanelVisible = !appState.ui.isMainPanelVisible; if (appState.ui.isMainPanelVisible) appState.ui.isFabMenuOpen = false; UI.render(); },
        toggleHistoryPanel: () => { appState.ui.isHistoryPanelVisible = !appState.ui.isHistoryPanelVisible; if(appState.ui.isHistoryPanelVisible) { appState.ui.isMainPanelVisible = false; appState.ui.isFabMenuOpen = false; } UI.render(); },
        toggleFavoritesPanel: () => { appState.ui.isFavoritesPanelVisible = !appState.ui.isFavoritesPanelVisible; if(appState.ui.isFavoritesPanelVisible) {appState.ui.isMainPanelVisible = false; appState.ui.isFabMenuOpen = false; } UI.render(); },
        handleTabClick: (toolId) => {
            if (appState.ui.activeToolId === toolId && appState.ui.isMainPanelVisible) {
                 if (UI.elements.tabContentContainer) UI.renderActiveTabContent();
                return;
            }
            appState.ui.activeToolId = toolId;
            appState.promptParams.artisanMode = toolId;
            GM_setValue(STORAGE_KEYS.ACTIVE_TOOL_ID, toolId);
            appState.generatedPrompts = [];
            appState.error = null;
            // appState.promptParams.description = ""; // Optional: Clear description on tab switch
            UI.render();
        },
        handleDescriptionChange: (e) => { appState.promptParams.description = e.target.value; Handlers.handleLivePreviewUpdate(); },
        handleNegativePromptChange: (e) => { appState.promptParams.negativePrompt = e.target.value; Handlers.handleLivePreviewUpdate(); },
        handleCandidateCountChange: (e) => { appState.promptParams.candidateCount = parseInt(e.target.value, 10); Handlers.handleLivePreviewUpdate(); },
        handleAudioLevelChange: (e) => { appState.promptParams.audioPromptingLevel = e.target.value; GM_setValue(STORAGE_KEYS.SELECTED_AUDIO_LEVEL, e.target.value); Handlers.handleLivePreviewUpdate(); },
        handleStyleChange: (e) => { appState.promptParams.style = e.target.value; GM_setValue(STORAGE_KEYS.SELECTED_STYLE, e.target.value); Handlers.handleLivePreviewUpdate(); },
        handleImageUpload: (e) => { const file = e.target.files[0]; if (!file) { Handlers.handleClearImage(); return; } if (file.size > MAX_IMAGE_SIZE_BYTES) { UI.showGlobalMessage(`Image too large (max ${MAX_IMAGE_SIZE_BYTES/(1024*1024)}MB).`, "error"); e.target.value = ""; return; } if (!ALLOWED_IMAGE_TYPES.includes(file.type)) { UI.showGlobalMessage(`Invalid file type. Allowed: ${ALLOWED_IMAGE_TYPES.map(t=>t.split('/')[1]).join(', ')}.`, "error"); e.target.value = ""; return; } const reader = new FileReader(); reader.onloadend = () => { const b64 = (reader.result).split(',')[1]; const previewUrl = URL.createObjectURL(file); appState.promptParams.uploadedImage = { b64, mimeType: file.type, name: file.name, previewUrl }; UI.updateImagePreview(); Handlers.handleLivePreviewUpdate(); }; reader.onerror = () => { UI.showGlobalMessage("Failed to read image.", "error"); appState.promptParams.uploadedImage = null; UI.updateImagePreview(); Handlers.handleLivePreviewUpdate(); }; reader.readAsDataURL(file); },
        handleClearImage: () => { if (appState.promptParams.uploadedImage && appState.promptParams.uploadedImage.previewUrl) URL.revokeObjectURL(appState.promptParams.uploadedImage.previewUrl); appState.promptParams.uploadedImage = null; if (UI.elements.imageUploadInput) UI.elements.imageUploadInput.value = ""; UI.updateImagePreview(); Handlers.handleLivePreviewUpdate(); },
        handleAdvancedSettingChange: (e) => { const key = e.target.dataset.advKey; if (key && appState.promptParams.advancedSettings.hasOwnProperty(key)) { appState.promptParams.advancedSettings[key] = e.target.value; Handlers.handleLivePreviewUpdate(); }},
        handleClearAdvancedSettings: () => { UI.createConfirmationModal("Reset Advanced Controls to their defaults?", () => { for (const key in SCHEMA_INPUTS) appState.promptParams.advancedSettings[key] = SCHEMA_INPUTS[key].default || ''; appState.promptParams.advancedSettings.aspectRatio = VEO_ASPECT_RATIOS_VALUES[0]; appState.promptParams.advancedSettings.durationHint = VEO_DURATION_HINTS[0]; UI.updateAdvancedSettingsInputs(); Handlers.handleLivePreviewUpdate(); UI.showGlobalMessage("Advanced settings reset.", "info"); }); },
        handleLivePreviewUpdate: () => {
            if (!UI.elements.livePreviewArea) return;
            const modeConfig = ARTISAN_PREAMBLE_CONFIG[appState.ui.activeToolId];
            if (!modeConfig || !(modeConfig.type === 'generation' || modeConfig.type === 'extension')) {
                UI.elements.livePreviewArea.textContent = "Live AI instruction preview not applicable for this tool."; return;
            }
            let preambleBaseText = modeConfig.getPreambleText({ candidateCount: appState.promptParams.candidateCount, audioPromptingLevel: appState.promptParams.audioPromptingLevel });
            let imageInfoString = ""; if (appState.promptParams.uploadedImage) imageInfoString = `[Image Provided: ${appState.promptParams.uploadedImage.name}]`;
            const userContentToInject = Utils.buildUserContentString(appState.promptParams, imageInfoString);
            const fullPreviewText = preambleBaseText.replace("[USER_CONTENT_PLACEHOLDER]", userContentToInject);
            UI.elements.livePreviewArea.textContent = fullPreviewText;
        },
        handleSubmit: async () => {
            const currentToolId = appState.ui.activeToolId;
            const currentModeConfig = ARTISAN_PREAMBLE_CONFIG[currentToolId];
            let inputRequired = true;
            if (currentModeConfig && currentModeConfig.requiresInputType === 'optional_seed_for_surprise') inputRequired = false;
            if (inputRequired && !appState.promptParams.description.trim() && !(currentModeConfig.type === 'generation' && appState.promptParams.uploadedImage) && !(currentModeConfig.type === 'extension' && appState.promptParams.uploadedImage) ) {
                UI.showGlobalMessage("Please provide the required input for this tool.", "warning");
                if(UI.elements.promptInput) UI.elements.promptInput.focus(); return;
            }
            appState.error = null; UI.renderAppStatus();
            await API.generatePrompts();
        },
        handleClearCurrentToolInputs: () => {
            UI.createConfirmationModal("Clear all inputs for the current tool (description, negative prompt, image)?", () => {
                appState.promptParams.description = '';
                appState.promptParams.negativePrompt = '';
                Handlers.handleClearImage();
                appState.generatedPrompts = [];
                appState.error = null;
                UI.render();
                if(UI.elements.promptInput) UI.elements.promptInput.focus();
                UI.showGlobalMessage("Inputs for current tool cleared.", "info");
            });
        },
        handleUseAsBase: (promptText) => { appState.promptParams.description = promptText; Handlers.handleClearImage(); appState.generatedPrompts = []; appState.error = null; if (!appState.ui.isMainPanelVisible) Handlers.toggleMainPanelVisibility(); else UI.render(); if (UI.elements.promptInput) UI.elements.promptInput.focus(); UI.showGlobalMessage("Prompt loaded as new base input.", "info"); },
        handleLoadFromHistory: (historyItem) => { const loadedParams = JSON.parse(JSON.stringify(historyItem.params)); appState.promptParams.description = loadedParams.description || ''; appState.promptParams.negativePrompt = loadedParams.negativePrompt || ''; appState.promptParams.candidateCount = loadedParams.candidateCount || DEFAULT_CANDIDATE_COUNT; appState.promptParams.artisanMode = loadedParams.artisanMode || Object.keys(ARTISAN_PREAMBLE_CONFIG)[0]; appState.ui.activeToolId = appState.promptParams.artisanMode; GM_setValue(STORAGE_KEYS.ACTIVE_TOOL_ID, appState.ui.activeToolId); appState.promptParams.audioPromptingLevel = loadedParams.audioPromptingLevel || DEFAULT_AUDIO_LEVEL; appState.promptParams.style = loadedParams.style || DEFAULT_STYLE_KEY; const freshAdvancedSettings = { aspectRatio: VEO_ASPECT_RATIOS_VALUES[0], durationHint: VEO_DURATION_HINTS[0] }; for (const key in SCHEMA_INPUTS) { freshAdvancedSettings[key] = SCHEMA_INPUTS[key].default || ''; } appState.promptParams.advancedSettings = { ...freshAdvancedSettings }; if (loadedParams.advancedSettings) { for (const key in loadedParams.advancedSettings) if (appState.promptParams.advancedSettings.hasOwnProperty(key)) appState.promptParams.advancedSettings[key] = loadedParams.advancedSettings[key]; } Handlers.handleClearImage(); appState.generatedPrompts = historyItem.prompts ? JSON.parse(JSON.stringify(historyItem.prompts)) : []; appState.error = null; if (appState.ui.isHistoryPanelVisible) Handlers.toggleHistoryPanel(); appState.ui.isMainPanelVisible = true; appState.ui.isFabMenuOpen = false; UI.render(); if (UI.elements.promptInput) UI.elements.promptInput.focus(); UI.showGlobalMessage("Loaded from history. Image (if any) needs re-upload.", "info"); },
        handleClearHistory: () => { UI.createConfirmationModal("Are you sure you want to clear all history? This cannot be undone.", () => { appState.history = []; Storage.saveHistory([]); if (appState.ui.isHistoryPanelVisible && UI.elements.historyModal) { UI.elements.historyModal.remove(); UI.elements.historyModal = null; if(appState.ui.isHistoryPanelVisible) Handlers.toggleHistoryPanel(); } UI.showGlobalMessage("History cleared.", "success"); UI.render(); }); },
        handleToggleFavorite: (promptId, promptText) => { const existingIndex = appState.favorites.findIndex(fav => fav.id === promptId || (fav.id === null && fav.text === promptText)); if (existingIndex > -1) {appState.favorites.splice(existingIndex, 1); UI.showGlobalMessage("Removed from favorites.", "info", 1500); } else { if (appState.favorites.length >= MAX_FAVORITES_ITEMS) {appState.favorites.pop(); UI.showGlobalMessage("Max favorites reached. Oldest removed.", "warning", 2000); } appState.favorites.unshift({ id: promptId || Utils.generateId(), text: promptText }); UI.showGlobalMessage("Added to favorites!", "success", 1500); } Storage.saveFavorites(appState.favorites); UI.render(); },
        handleClearFavorites: () => { UI.createConfirmationModal("Are you sure you want to clear all favorite prompts?", () => { appState.favorites = []; Storage.saveFavorites([]); if (appState.ui.isFavoritesPanelVisible && UI.elements.favoritesModal) { UI.elements.favoritesModal.remove(); UI.elements.favoritesModal = null; if(appState.ui.isFavoritesPanelVisible) Handlers.toggleFavoritesPanel(); } UI.showGlobalMessage("All favorites cleared.", "success"); UI.render(); }); },
        handleCopyText: (textToCopy, buttonElement) => { if (!textToCopy || !buttonElement) return; GM_setClipboard(textToCopy, 'text'); const originalIcon = buttonElement.querySelector('.material-symbols-outlined'); const originalIconName = originalIcon ? originalIcon.textContent : 'content_copy'; if (originalIcon) originalIcon.textContent = 'task_alt'; buttonElement.disabled = true; setTimeout(() => { if (buttonElement) { if(originalIcon) originalIcon.textContent = originalIconName; buttonElement.disabled = false; }}, 1500); },
        parseAndApplyInferredParameters: (inferredText) => { let appliedSomething = false; const lines = inferredText.split('\n'); const parsed = { style: null, cameraAngle: null, cameraMovement: null, lighting: null }; lines.forEach(line => { const [keyDirty, ...valueParts] = line.split(':'); if (!valueParts.length) return; const key = keyDirty.trim().toLowerCase(); const value = valueParts.join(':').trim(); if (key.includes("style") && VEO_STYLES.includes(value)) parsed.style = value; else if (key.includes("camera angle") && VEO_CAMERA_ANGLES.includes(value)) parsed.cameraAngle = value; else if (key.includes("camera movement") && VEO_CAMERA_MOVEMENTS.includes(value)) parsed.cameraMovement = value; else if (key.includes("lighting") && VEO_LIGHTING_CONDITIONS.includes(value)) parsed.lighting = value; }); if (parsed.style) { appState.promptParams.style = parsed.style; GM_setValue(STORAGE_KEYS.SELECTED_STYLE, parsed.style); appliedSomething = true; } if (parsed.cameraAngle) { appState.promptParams.advancedSettings.camera_angle = parsed.cameraAngle; appliedSomething = true; } if (parsed.cameraMovement) { appState.promptParams.advancedSettings.camera_movement = parsed.cameraMovement; appliedSomething = true; } if (parsed.lighting) { appState.promptParams.advancedSettings.lighting_style_atmosphere = parsed.lighting; appliedSomething = true; } Handlers.handleTabClick(Object.keys(ARTISAN_PREAMBLE_CONFIG)[0]); if (appliedSomething) UI.showGlobalMessage("Inferred parameters applied to Generator settings.", "success"); else UI.showGlobalMessage("Could not parse or apply parameters from Suggester. Switched to Generator.", "warning"); },
        parseAndApplySurpriseMe: (surpriseText) => { let concept = ""; let appliedSettings = false; const lines = surpriseText.split('\n'); const parsed = { concept: null, style: null, cameraAngle: null, cameraMovement: null, lighting: null }; lines.forEach(line => { const [keyDirty, ...valueParts] = line.split(':'); if (!valueParts.length) return; const key = keyDirty.trim().toLowerCase(); const value = valueParts.join(':').trim(); if (key.includes("concept")) parsed.concept = value; else if (key.includes("style") && VEO_STYLES.includes(value)) parsed.style = value; else if (key.includes("camera angle") && VEO_CAMERA_ANGLES.includes(value)) parsed.cameraAngle = value; else if (key.includes("camera movement") && VEO_CAMERA_MOVEMENTS.includes(value)) parsed.cameraMovement = value; else if (key.includes("lighting") && VEO_LIGHTING_CONDITIONS.includes(value)) parsed.lighting = value; }); if (parsed.concept) appState.promptParams.description = parsed.concept; if (parsed.style) { appState.promptParams.style = parsed.style; GM_setValue(STORAGE_KEYS.SELECTED_STYLE, parsed.style); appliedSettings = true; } if (parsed.cameraAngle) { appState.promptParams.advancedSettings.camera_angle = parsed.cameraAngle; appliedSettings = true; } if (parsed.cameraMovement) { appState.promptParams.advancedSettings.camera_movement = parsed.cameraMovement; appliedSettings = true; } if (parsed.lighting) { appState.promptParams.advancedSettings.lighting_style_atmosphere = parsed.lighting; appliedSettings = true; } Handlers.handleTabClick(Object.keys(ARTISAN_PREAMBLE_CONFIG)[0]); if (parsed.concept) UI.showGlobalMessage(`Surprise concept: "${parsed.concept}" loaded. ${appliedSettings ? "Suggested settings also applied to Generator." : "Switched to Generator."}`, "info"); else { UI.showGlobalMessage("Could not fully parse surprise concept. Switched to Generator.", "warning"); if (appState.generatedPrompts.length > 0 && !appState.promptParams.description) appState.promptParams.description = appState.generatedPrompts[0].text; } }
    });

    // --- INITIALIZATION ---
    function main() {
        if (hasInitialized) {
            console.log("VideoFX Prompt Artisan: Attempted to initialize more than once. Aborting redundant initialization.");
            return;
        }
        hasInitialized = true;

        console.log(`VideoFX Prompt Artisan v${SCRIPT_VERSION} Initializing...`);
        try {
            Handlers.initAppState();
            UI.init();
            UI.render();
            console.log("Artisan: App State Initialized & UI Rendered.");
        } catch (error) {
            console.error("CRITICAL ERROR during Artisan Initialization:", error);
            const errorDiv = document.createElement('div');
            errorDiv.style.cssText = 'position: fixed; top: 20px; left: 20px; background: var(--artisan-error, red); color: white; padding: 20px; z-index: 20000; font-size: 16px; border-radius: var(--artisan-radius-main, 8px); box-shadow: var(--artisan-shadow-large); font-family: var(--artisan-font-primary, sans-serif);';
            errorDiv.innerHTML = `<strong>FATAL SCRIPT ERROR (v${SCRIPT_VERSION})</strong><br>${error.message}.<br>Check console (Ctrl+Shift+J or Cmd+Opt+J) for details.`;
            try { document.body.appendChild(errorDiv); } catch(e) { console.error("Could not append fatal error message to body:", e); }
        }
    }
    function runMainWhenReady() {
        if (document.readyState === 'complete' || (document.readyState === 'interactive' && document.body)) {
             main();
        } else {
            window.addEventListener('DOMContentLoaded', main, { once: true });
            setTimeout(() => {
                if (!hasInitialized) {
                    console.warn("Artisan: DOMContentLoaded fallback timeout, attempting main().");
                    main();
                }
            }, 3000); // Increased timeout slightly
        }
    }
    runMainWhenReady();
})();
